I am happy to hold you guys accountable on your projects! Leave some of your ideas in the section below to make sure that you will do them. Also, make sure to subscribe and turn on notifications to be alerted when part 2 comes out on Monday!
Can I put this project in my resume for internship ??
thank you thank you thank you! a thousand times thank you!!!!!!
Hi , can you please let me know where can I get a live dataset for market mixing model project
https://codeverse001.blogspot.com/2023/08/data-science-in-sports-analytics.html
Hey, this is Amazing. Just wanted to know, I am an absolute beginner in Data science. So should I be doing this? Will I be able to understand data science after this or should I complete some prerequisites before starting this project?
Stumbled upon this video as I'm in in the middle of coop search term. Will it help in any way if I included whatever I did in this series in my resume ?
Thank you for the feedback Ken sir !!!
Awesome video but i have questions what are the key skills that an undergraduate student must have to secure or placed in data analytics and what about career improvement? Please sir answer the question i m lot of confused there.
From where we can collect data apart from Kaggle?
one of the things in the video is the background music. somehow that keeps us glued in the video and also you content is amazing sir. Thank you for this.
Thank you, even just this intro made me much more confident about my current university assignment.
What are the prerequisites(skills)for this projects? What should I learn before this project.
Thanks a lot for uploading detailed and crisp DS project. This is really helpful !!
Sir please help how we train model and do some prediction in data cleaning project.
hey ken , thank you so much for this appealing effort that you are doing
Oh my god this is exactly what i want thank you thank you thank you.God bless you and guide you to the right way
Would love a sports DS project from scratch
Very underrated channel! I believe i just found a diamond in a haystack!
RObust talking bro
Hey Ken ! Thank you for creating an amazing platform for us to not get overwhelmed with data science. This is my start of data science journey. I am so glad to be here. More power to you :)
should i know about machine learning to watch this playlist?
woo! Thanks!
I am starting a transition to data science from etl. Can you pls guide
Is there any job as sports data scientist? because i am a big football fan and also interested in data science
It's very good. How ever,  I try the code, it's not working.
It will be wonderful
Can anyone who attended product company interviews/ working as data scientist in product company guide me what topics are must for data scientist  interviews in a product company...
      Also am interested to know the importance of data structure& algos , probability statistics  in these interviews for experienced candidates..
Sir! please tell me of I am going in the right Direction. 
I had done Training in Machine learning and that training focused less on working with data and more on Algorithms.
I stopped learning ML and have heavily focused on working with Data and Understanding it. 
Now I am working on BI and planning to work on ML after it. 
Am i on the right track?
amazing stuff didnt even know i needed this
Hi Ken, Thanks for your video. I need to do a project and I don't know what topic to choose. Any ideas?. Thanks a lot
https://www.youtube.com/watch?v=PwBeP0E0Tdw
please make a road map video
What is the minimum skill to get intothis project? Python, Numpy, pandas, matplotlib all done. Am i good to go to this? Or need more skill like ML?
You are phenomenal and so is this series! I am primarily a spatial and kinetic learner and for some reason, I'm insane with statistics and probability though I tend to forget the formal terminology and theories that I actually implement. I've been wanting to find a way to learn hands on then get the terminology later on, since I'm in school full time, working full time and beginning my first start up so this series is helpful and simply perfect for my schedule.
Hi! I am already following this series and this morning I was reading an article about a man who got an interview from the first data science job he applied for; he started his data science journey by following this series too! The article is by Mario Paul at Towards Data Science titled: "I Got An Interview From The Only Data Science Job I applied for." This is so awesome!
Okay so I been following your work for few months and I didn't came across this data science project from scratch series but anyway starting from today .
Ps: I came to know about this from @andrewmomoney channel video on data science bible for 66 daysðŸ’¯ðŸ¤›ðŸ‘
That's great!! , I think mastering the skill of working on projects and uploading and using them in making a powerful personal portfolio is the keyword of being professional in the field and getting finding good job , so plz we need more of that staff
Great Playlist Ken, This is me Fahad from my other channel where I teach Data Science in Arabic, do  have a look at my channel there are some English videos, Thanks man, Keep up the good work
Awesome series. Thanks a lot!
Thanks so much Ken, it's very helpful to outline all the major parts of the project like you did.
Ken, first of all, thanks a lot for making the series. I wanted to ask your opinion of a fresher (me) doing a project on the credit risk analysis from kaggle. As tons of people have done a lot of work on this already, do you think its worth working on it ? do you think it could be interesting enough to be put on the resume?
Hi ken, I am struggling to find an affordable desktop computer or laptop ( No more than 400 USD ) that would help me open and use IDEs and other tools fast and comfortably, I would really appreciate it if you could give me your recommendations as my laptop is really slow. Thank you
My new favorite series on Youtube  :) Thank you Ken JEE
This is perfect. Please add more like this and explain why you are doing the steps. Most teach but dont explain the reasoning. A series on basic DS projects would be awesome.
thank you so much for making these videos! Very informative!
Hello sir thanks for this project. Can you please make a video on datascience project using image datasets
Thanks for the great content!
Love this series. This is exactly what I need help with right now. Thank you so much....You're rock Ken :)
Hey, I just started watching your videos. Great content ! Looking forward to follow this series.
FYI: You are awesome !
hello ken sir,
I am having a consulting firm in india for a costing and taxtion work... i have team for the same, I want to start now in new field of data science  as my firm is set and these is really good analytical field which i will like to work on.
I find your videos really interesting and showing the way ahead . I want to make you my mentor.
Thanks & Regards,
Deepali (India)
Hi Ken, 

If I follow along with the project but do it for different cities in India, do I have permission to put it on my github or does it class as plagiarism. If so, I won't be sharing it online. Of course, I will write about your work,link  and mention the original idea in the Readme. Is it intellectual property theft if done this way?
i just Beginner i need to understand how to know Business requirement  or how to understand this  Business ?
I want to start in kaggle projects ,please recommended for me some project i can solve ,thanks
Ken we would love to see more series like this . Totally loveddd it !  .
Hi Ken, I want to thank you for your content, I find it really helpful :), Also I had a few questions that I wanted to ask you! what would be a good place to shoot questions? Thanks!
I love you Ken. I have not paid attention to the series as it is focused on data science (I am a data engineer, just starting though) not when I saw the 5th video of the series then I read the description. There is so much to take away for this. Thanks
what to do when robots.txt show's disallow should you proceed? Cause if you show this to a hiring manager he might take it as a red flag for ethics.
Can't thank you enough
Hey Ken, thank you so much for this. I am currently trying to transition from consulting to data science, but have been really struggling to find ways to demonstrate my knowledge to potential employers. This really helped! Projects don't look like so daunting now!
Thanks for this wonderful project walk through.  You are my teacher now.
Cool man...
Thank you Keen for this series ! I"ll be thankful if I'll see more videos from you ! Good Job Man
Hey Ken, the quality of your videos are getting better and I am enjoying this series. thank you for this content!
Thank you for the Data Science project from scratch videos series.
Just getting into your work. Thank you so much learning more from you than I am in class
Thanks Jen i am national lawn tennis player and want to be a data scientist the moment I saw you writing tennis I hit the like button ,this is the perfect one for me to startup with
Please do something on soccer
Looking forward to part 2 :)
This is a great video! Thank you
nice. I am working on my first proper project & would like to see how pros go about it.
This is real helpful. Thanks for the video :). IÂ´m excited to see the more!.
discord? only respond with a date! hahaha
Finally !! Thank you Ken !
I'm so excited for this series!
Good work, keep rocking ðŸ¤œðŸ¤›
i hope this will help me on my final project.
waiting for the next video
Keep it up, thanks for the great content!
Thanks man! Eagerly waiting to end the whole project with you. My first DS project *_*
Hi Ken, I'm glad I stumbled upon your channel. Looking forward to see more of your upcoming videos. Project videos are a great idea, keep it up!
Another great video. Showing us how to think and plan rather than just spitting out explicit answers. Excited for the future installments.
Thank you for this addition! I think I want to start with linear regression on premier league soccer and predicting final league standing from early-season information.
Men! I was waiting for this. Thank you very much!
Instagram Human mimic AI bot.
Using autoencoders to mimmic human behavior.
Data Science Part 2
Go to kaggle and see the project.
Awesome content! Still relevant in 2024!
Can't we scrape the data just by using beautifulsoup.. is selenium knowledge is required?
Im getting this error Im struck ..Please help me with this error SeleniumManagerException: Message: Selenium Manager failed for: /Users/mahalakshmirajabattula/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/common/macos/selenium-manager --browser chrome --output json.
The chromedriver version cannot be discovered
It is showing ->
 Scraping terminated before reaching target number of jobs. Needed 15, got 0. 
Please help
Hi Ken, Great work @12:35 I got this error "IndentationError: unindent does not match any outer indentation level"
bro you got all modules installed but some people aint got , plz show how to install modules also
Can anyone here help me with this project
Thank you so much,finally after a week I completed this video with solving all errors i got ,i learnt so much and learning.
Could you share the link of your background music plz?
i can't find the glassdoor_scraper module to install, how do i go about it please?
i'm having trouble in using the jobs button, can some one help
I did everything u did at the start but I just couldn't get it to work, I already put the right path for my chromedriver but its not working, it says this error :
"TypeError: WebDriver.__init__() got an unexpected keyword argument 'executable_path' "
Hello sir, I have a question,
If we give a list of locations so it will change location by itself after completing scraping of jobs in one location? 
I am waiting for your response.
Thank you sir for making such a good videos for us.. these are very helpful.
8:53 you can select the first word of the with a double click and then go to the end of the code and then Shift +  click on the last code you want to select. And there you go. I find this easier.
I'm stucked in the finding the x part. The structure of glassdoor changed so I updated the class but I still get 'x out failed'
your position in front of a computer is wrong, care for your health, and thanks for tuts
Hi Ken I am not able to see screen clearly now it's bluring
In order to copy many lines of code, 
you can highlight the first couple words in the code, then scroll to the end of the code you want to copy.
Then hold shift button and click with the mouse the end of the code.
Should the aspiring data scientists be aware of Web Scapping? Should we learn about selenium and beautiful soup? Or is this the work of a data engineer?
: 'WebDriver' object has no attribute 'find_elements_by_class_name'
help >>>
When I get to the scraping part I am unable to move on...I get a message saying "Error Loading , please try again"...I am doing it on Jupyter notebook....could you plz tell me where I am going wrong


On jupyter notebook the error points at 

--> get_jobs("data science ",15, False, 15) 

--> driver.find_element_by_class_name("selected").click()


AttributeError : 'WebDriver' object has no attribute 'find_element_by_class_name'
18:46
1) Import files 11:30
Selenium
14:30-
is the chromedriver at the end important ?
12:35
can you please help how to deal with this? Scraping terminated before reaching target number of jobs. Needed 15, got 0.
hello sir your explanation is very good but i am getting an error like this ..

    df = gs.get_jobs('Data Scientist',1000, False, path,15)

  File ~\salary_project\glassdoor_scraper.py:39 in get_jobs
    driver.find_element_by_class_name("selected").click()

AttributeError: 'WebDriver' object has no attribute 'find_element_by_class_name'
Thanks for the video. I use Jupyter nootbook. How to solve such error 'ModuleNotFoundError: No module named 'glassdoor_scraper'?
'Scraping terminated before reaching target number of jobs' - any leads to solve this error?
though I'm a fresher & could not understand a single code in the whole video, I simply sit back and  watched how simple he is doing his work ??
can I use scraping tools like Instant Data Scraper or some other tool for the purpose of data collection?
Lovely playlist Ken!! thanks a lot , as a beginner going through this made me understand the working process!
Can anyone please share selenium python code, iam not able to fetch the data..
Hi Ken! I'm a little late here but I'm getting stuck trying to run the initial web scraper and getting the following error after printing 'Progress: 0/15'



ERROR:ssl_client_socket_impl.cc(996)] handshake failed; returned -1, SSL error code 1, net_error -200
 x out failed
Scraping terminated before reaching target number of jobs. Needed 15, got 0.


What seems to be happening (based on the message and looking at the screen as it attempts to scrape) is that the code is either not properly able to exit from the 'Sign Up' pop-up or maybe it's not able to click on a posting. 

I've been scratching my head at this for a while now and I'm really stuck. I'm using your code now directly from your GitHub. Anything you recommend trying? I love this series and am finding it very helpful but would love to follow along.
Can you please maje another same Blog on web scraping
Thanks you Sensei Ken jee
Little complicated but worth watching because I learned a few new things. I couldn't make it run though so moving to the next video and will use your data file. I will come back to this video in the future after I learn some Selenium. Thank you for this unedited video!
Hello Ken Jee, 
i was trying this code, but in my case the below line is returning a empty list. 
job_buttons = driver.find_elements_by_class_name("jl")
@Ken this content is gold and qualitative in terms of pushing individual horizons to do trial and error and build stuff~

Anybody who was able to solve the issue of scraping the job_buttons off the current Glass door website please lend your help, the website has changed and it no longer accepts 'jl' as the class name for those elements thanks. :)
Hi Ken,
I followed your scrapping process. After following the process you did to get rid of sign up prompt and when I run the scrapping, it gives me the following error


"x out failed
Scraping terminated before reaching target number of jobs. Needed 5, got 0."
I really enjoy this natural approach, picking up real examples without preparation, it feels more genuine, great video, thanks
I'm from Syria and I am working on Data Science Project from Scratch - Part 2 (Data Collection) and I replace the code from driver.find_element_by_class_name("ModalStyle__xBtn___29PT9").click() to  driver.find_element_by_css_selector('[alt="Close"]').click() but the photo will not show ''   Sign In to get instant access to millions of salaries and reviews
By continuing, you agree to our Terms of Use and Privacy Policy."
'and output is  x out failed
Scraping terminated before reaching target number of jobs. Needed 15, got 0. 
Note : in Syria we need to VBN with glassdoor
Team or anyone who can guide me how to create a creating a web scraping file
Great video ! However, is it possible that : "job_buttons = driver.find_elements_by_class_name("jl")" does not work anymore ? where did you find it in the HTML code ? if I print the job_button in job_buttons, I get an empty list. thanks a lot !
Hey, it's not working for Microsoft Edge Browser. Error: AttributeError: module 'selenium.webdriver' has no attribute 'EdgeOptions'
are anybody getting errors with import glassdoor_scraper as gs?
Hi Ken, Thank you for the video it was very informative. However, I ran into a problem where I ran the code it says "Scraping terminated before reaching target number of jobs. Needed 15, got 0". Any advice on this?
Awesome series! Can you do another series like this- maybe with a more complicated project?
i dislike the programming practices but i love to see people getting passionate about their trade, so for that, i respect ken jee. video's pretty old, i hope u got better with  some of the stuff u do with python, github, etc. lol but that's ok, nbd, i suppose, but it obviously wouldn't hurt and i imagine it's pretty common among people who use programming but are not programmers..  sorry just commenting out-loud.
for 18:27 which got succeeded in scrapping, mine is getting terminated? what can be the solution?
Hi Ken, what the steps for creating a web scraping file
I have tried this too many times but the only result I got is "Scraping terminated before reaching a target number of jobs".Please if someone can help how to fix it.
Hi , getting the following error on trying web scrapping, pls help with this

<ipython-input-3-9f35248b0e1a>:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object
  driver = webdriver.Chrome(executable_path=path, options=options)
<ipython-input-3-9f35248b0e1a>:27: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead
  driver.find_element_by_class_name("selected").click()
<ipython-input-3-9f35248b0e1a>:33: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead
  driver.find_element_by_css_selector('[alt="Close"]').click() #clicking to the X..
<ipython-input-3-9f35248b0e1a>:40: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead
  job_buttons = driver.find_elements_by_class_name("jobLink")  #jl for Job Listing. These are the buttons we're going to click.
 x out failed
Progress: 0/15
<ipython-input-3-9f35248b0e1a>:53: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead
  company_name = driver.find_element_by_xpath('.//div[@class="employerName"]').text
Thanks Ken for such a informative tutorial
Could someone help me with this issue?
Scraping terminated before reaching target number of jobs. Needed 15, got 0.
Great video Ken! Thank you so much for sharing.
I feel so satisfied seeing you copy the codes. I thought only freshers does that
In my case it was not so easy like copy-paste, I found a scrapper from 3 years ago ðŸ˜…ðŸ¤­ i'll should do by myseld, and i think write a blog of something, ðŸ¤”
Since im in Europe scrapping for me is not working as i think the allow cookies part is stopping it from scrapping, any suggestions on how to bypass that?
Hi Ken, how did you achieve 12:46 by doing the 11:25 part? Did you create a new file?
Is it just me or glassdoor has made its html scrape-proof? I tried reproducing the code but I couldn't comprehend how I could access the elements with company name, salary est., location, etc. The elements are just divs with job ids in class name and no extra attributes to access them. Anyone have a workaround, please help? If possible, can anyone share the link with the dataset you scraped because I really want to follow along with the tutorial. Thanks in advance
Hey, do we need to install anaconda or is just spyder okay?
Can someone please help understand the below error I am getting,
" Unable to locate element: {"method":"css selector","selector":".selected"} "
Ken, I envy your ability to build something of value so quickly. ðŸ¤–
Hello, I am trying to use the code to extract information from glassdoor but code is no more working may be due to changes in glassdoor . can you suggest
As much as I admire this series, blindly making a tutorial where your copy and pasting code as part of a tutorial -- which is aimed at beginner's is not the best way to teach, as more often than not, they won't understand what's going on, selenium is easy enough to read the docs for, this could of been achieved by showing your process how you would do this on your own.
Hi Ken

After making suggested changes in Glassdoor_scrapper code when I try to import as module in new window but It shows following error "ModuleNotFoundError: No module named 'glassdoor_scrapper'". Please help me to address it.
Hello Ken Jee, thanks a lot for the playing. It is awesome for newbies like me!

I am trying to follow along with the video, but I get the following error: "<input>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead"

I am trying to replace all "find_element_by_xpath" with find_element(by=XPATH, value = xpath) but I cannot figure out how to make it work! 

I would highly appreciate any advice!
I LIKE YOUR TEACHING WAY BHAI!!
How to copy multipage code:    ( BTW yours videos are awesome .. like real crispy and to the point ) 
1. Mouse click on the starting position say .. def 
2. scroll down ( No mouse selection .. just scroll ) the position to the point  and the click while you hold the shift button.. 

* Please ignore if someone already suggested the same..
Would be good ot mention that some websites (like glassdoor) are updated all the time and that this script won't work after a while
Hello Ken 
I am running into this error.... please assist 

ModuleNotFoundError: No module named 'glassdoor_scraper'
AttributeError: module 'glassdoor_scrapper' has no attribute 'get_jobs' ----- this is the error im getting. send help
Can someone help me with installing the chrome driver?
Could someone help me with this issue?
Scraping terminated before reaching target number of jobs. Needed 15, got 0.
Thank you so much for this series! I am planning on transitioning to data science and I'm new to its programming aspects. How did you know what to do at 15:29? I figured that was HTML code. Do I need to learn HTML to be able to spot and fix those errors? Thanks again Ken!
NoSuchElementException: no such element: Unable to locate element: {"method":"css selector","selector":".selected"}
  (Session info: chrome=92.0.4515.131)

I'm getting this error during scraping data
@Ken Jee I am facing this error, I googled it but didn't find any solution. I am very new to this so if anyone know how to get done with this.
 no such element: Unable to locate element: {"method":"css selector","selector":"[alt='Close']"}
  (Session info: chrome=92.0.4515.131)
8:52 Ctrl+a selects all the text on a page. That might be a bit anything to clean up though.
Hello, I am on Mac using Python 7.22, since this video was made, I am sure there are some changes to the code. I am getting 'str' object has no attribute 'click' as an error on most of the lines ending in .click(). Does anyone have a solution for this? I am fairly new to this and really want to get through the project but have been stuck here for days.
Thank you for this inside look.
Hello Ken.Can u fix the error of no such element: Unable to locate element: {"method":"css selector","selector":".selected" please. Thank You.
print('x out worked')
        ^
SyntaxError: invalid syntax
why am I having this error? Can someone help me, please
Sir is it possible to do this complete project  raspberry pi 4??
Hi I tried to re create this am getting an exception 
no such element: Unable to locate element: {"method":"css selector","selector":".selected"

how do i fix this? any one
Hi Ken. Great video. Following along, but it seems Glassdoor changed their class names especially infoEntity from the parser. Any suggestions on how to workaround this?
whenever i launched selenium it says that it cant locate  element method css selector selector selected
i spent  two days preparing and learing this project and i am stuck at 17:00. i am getting this error Message: no such element: Unable to locate element: {"method":"css selector","selector":".selected"} 
if someone has got the solution, let me know. I already searched a lot on internet but didn"t find solution. i replaced the glassdoor website with indeed.com too but the same error on  indeed. Also i changed the sleep time from 1 up to 500 but still no luck.
Hi I am getting the error :
NoSuchElementException: no such element: Unable to locate element: {"method":"css selector","selector":".selected"}
  (Session info: chrome=90.0.4430.212)

Have downloaded the correct version of chrome still getting the issue.

Please Help!!
Thank you for this great video!!! I am trying to scrap data more than 30 rows, it failed when it scraped into page 2. The error shows ElementNotInteractableException: Message: element not interactable
  (Session info: chrome=90.0.4430.212) Does it means this code did not write the case when scrapping more than one page.
Hi, when I try to run the scraper  I just get stuck on chrome opening with the message "Chrome is being controlled by automated test software". I don't know what could be causing this.
i got this error while running: OSError: [WinError 193] %1 is not a valid Win32 application
EDIT: I solved this problem by adding anaconda3 to path variables, but now I can't click the Close button. I tried many ways to do this but since 3 hours I still CAN'T Do this... I surrender.
Hey ken!
I am getting the same error as you got when you changed the 'find_element_BY...' 
please help me out
Hi KenJee! 
Firstly I code manually then I got below error and after that I copy & paste your code from GitHub then also I got same error....Can you give solution for me...Thank you so much...
Error - NoSuchElementException: no such element: Unable to locate element: {"method":"css selector","selector":".selected"}
  (Session info: chrome=90.0.4430.85)
The fact that you make this video with no cuts, showing us the whole process, trial and error and everything, makes this so unbelievably valuable. There's thousands of data science videos and how tos online, but I've never seen someone who lets me look right over their shoulder during the process. Kudos.
How did I not know of this before! Brilliant work man. Thank you so much for doing this!
why keyword is written
sir i am getting this type of error....plz help me out

  import glassdoor_scraper  as gs

ModuleNotFoundError: No module named 'glassdoor_scraper'
Im guessing since this a bit old now the code doesnt work cuz all class names are different!
Hello Ken, i'm new to data science, i watched your videos which i find very interesting. i got an error when i try to reproduce your tutorial. the error is << selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":".selected"}>> can you help me solve this problem so that i can continue the tutorial.
thank you
Having this error -- NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":".selected"}
  (Session info: chrome=89.0.4389.114)
PLEASE HELP
Thank you. Dying to see a real process that worked
9:00, why not just use ctrl + A / cmd + A to copy the whole cell?
Hi!, I'm having problem to get the data, apparently the problem is arround this line of code when trying to bypass the sing up thing:

try:
        driver.find_element_by_class_name("selected").click()

I get the error: NoSuchElementException: no such element: Unable to locate element: {"method":"css selector","selector":".selected"}
  (Session info: chrome=89.0.4389.90)

why does it not find the element?

Thanks in advance!
can any one tell me what do i have to put in the path variable at 12:12 i dont use chrome
I am always getting this error . Can you help me with that
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":".selected"}
  (Session info: chrome=89.0.4389.82)
Hello Ken, Thanks for uploading this helpful series. It is really helping me understand the basics very well! :) 



I had a question about data collection. Is data collection supposed to be a one-time process or does it have to be repeated over when the data in the source has changed? Taking the example of glassdoor, the data around salary will change over time, so how do we decide how often we should re-collect the data? And what if the website structure changes so often and hinders the scraping process? For example, this data scrapper code we referenced doesn't work very well if I run it now as many locators have changed, so I would also have to keep up with the changes in the glassdoor web structure. How to mitigate this problem?
This is huge; exactly what I was hoping to find because I couldn't visualize what a data science project really even means, where to start, etc - I'm learning on my own. I greatly appreciate the unedited process for tweaking the scraper. That stuff could be passed off as a bullet point "collect data", but we all know that even folks that do this daily spend some time going through what you went though in this video. 

If anyone else is working on a raspberry pi or Linux system, and has issues with selenium.. let me know. I went down a rabbit hole figuring out how to set it up.
Unfortunately this code is broken now. I think Glassdoor has made some changes. For example, class "jl" is now "react-job-listing". I've made a little progress in making some changes.
Is this script still working for you? I grabbed the code from your repo. I keep getting a NoSuchElementException "Unable to locate element: {"method":"css selector","selector":".selected"}"
Hey Ken, really good content, thank you so much. There's nothing like these series, looking forward to more of these type of series.
Tried almost everything but getting this error:  Message: no such element: Unable to locate element: {"method":"css selector","selector":".selected"}.
ugh. im not sure what im doing wrong. I keep gettingÂ 
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":".selected"}.Â 
Does anyone have any idea how to fix?
At 11:25, How did you go from a fully coded screen to just 5 lines of code when the driver path and other things were typed in? After you said, "Let's run this", I have no idea what you did to remove all that code, and just wind up with only 5 lines of code.
you can select all the code all at once by holding down 'command/shift'. Just keep holding down command/shift, and the previous code will not deselect.
Loved the video!!!!
please can someone help me 
i can't install glassdoor package 
i'm using pip3 and i have python3 install but when i run the pip3 install glassdoor command on my command prompt  i get a verry long error message
which at the end says invalid syntax
How can I install glassdoor scraper?
Hello Ken, Thank you for this tutorial.. 
Need a help..
"alt=close" not working.. cant find close button in the Inspect as well.. please help as to what key to fetch in.. Much Thanks:)
To copy a full code cell you click in the code cell and use CTRL +  A which would highlight everything the CTRL + C to copy everything. Great vid!
yeah there's a better and easy way to copy the entire script 
first, off you highlight the entire script by clicking at the beginning of the first line of the script and then scroll down to the end (make sure you don't click anywhere else) now hold the shift key and click at the end of the last line of code (while still holding the shift key)it will then highlight the entire script and now u can press ctrl+c to copy it.
this is greater stuff that I have come across I'm new to data science and I spend over a month on youtube trying to get me started with the journey but didn't really find a step by step tutorial as simple and straight forward for a beginner like this channel right here.
thanks, bro  its really so helpful 

please can you make a video on git bash and how to connect it to GitHub?
the process stops at: "Progress: 0/15". No error message whatsoever. :/ Anybody has an idea why?
Hi Ken, I am trying to use your scraper, but it is not scraping, it just shows "x out worked Progress: 0/15" and that is it. Do I have to download something else? Im a beginner!
i got that error 
from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException
Ken, i'm going through this entire project with you:) As selenium goes through the glass door website i get the error after a few cases saying ElementNotInteractableException ... i have added this error to the webscraper.py and like the other errors added pass but the error is reoccurring....can i get some advice?
I was facing an issue while scrapping.

Search as per keywords was not happening.

To tackle that I had to add the following code just below the "#clicking to the X." try block.

Code :- 
        try:
            driver.find_element_by_id('HeroSearchButton').click()
        except NoSuchElementException:
            pass

##I'm just clicking on search before scrapping.
## Make sure it executes only once
Thanks for the content @Ken
When scraping the 600th job there is no progress in scraping anymore and when I look into chrome I see a reload button and when I click it by myself then a "StaleElementReferenceException: stale element reference: element is not attached to the page document" Error is thrown. But before clicking myself at the reload button, there is no error thrown nor progress anymore. Does anybody knows a solution to that problem?
Having issues  with the chrome driver
Thank you for an informative tutorial. I am having the following error while running the code: OSError: [WinError 193] %1 is not a valid Win32 application
To copy the selenium scraper in one go just go to the first line of the code block and click so that your cursor is flashing, then scroll down to the bottom, once you get there, hold shift and click again and that will highlight everything between the two points where you click with your cursor

Huge time saver :)
Had some issue understanding the scrapper part because IDE is in dark mode but other than that understood very easily 
Thank youðŸ˜ŠðŸ’¯
I am not getting salaries in my data frame(It's coming -1 as default)
I did some digging, but I am not getting it.
Please help!!!!!
** ERROR (HELP)
When changing the Grey small salary to grey salary still no results.
Went in and inspected the element it is written as (CSS-1uyte96 CSS-hca4ks e1wijj24) which should be grey salary

If anyone has any insight on this and could help I would greatly appreciate it!
I'm getting some random css number as the span class name (css-1uyte9r css-hca4ks e1wijj242) of the salary estimate. When I'm entering that name in the scraper code, its returning -1. Any idea how to overcome this?
Amazing job Ken. I will definitely give you credits for my first project.
hey, ken wonderful video , i faced an error while copying the data soo many a times i used to get this output  (x out failed) in the middle of the extraction, and then suddenly it just paused at 622 /1000 like didnt pause but its just stuck there idk what to do @ken
07:38 scraping Jupyter Notebook into Spider IDE ðŸ¤£ðŸ˜‚
Hi ken, thank you for the video tutorial. However, my code works in reverse. The 'keyword' search works at the end of the Scrapping. Any help?
My scrapper gets stuck when getting the data...Any suggestions to resolve??
All the indian guys trying this project , use the data directly present in the github repo , dont run scrapper coz indian version of glassdoor is a bit differnt imo.
Hi Ken, amazing content, never come across such a thorough video (especially data scrapping part). Big fan of playingnumbers.com too. Can you make a video of the same type for a data visualization project maybe using tableau.
cant import glassdoor_scraper as gs. anyone knows why?
Hello I wanted to ask that I want data related to job profile- Data Scientist and Job location as Bangalore. When I searched in glassdoor.com the salary for the jobs posted in bangalore is not specified so any help here would be appreciated.
Thanks Ken!! you are the best. I manage to get my hands dirty. but I am curious about starting up my own scraping using another problem. can I still make use of the same function?
Great approach for working on a good project. Thanks for sharing. I'll get my hands on it when I master my basics
Hi Ken ...Project from scratch series really helps me to understand how does data scientists works on real world project in their companies...Thank you so much for your efforts...very appreciating ... looking for more such kind of projects from you.
@12:56 how do you run the browser ?

am getting this: WebDriverException: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home
I do not know why all salary estimate values are repeated,  I followed your video and fix it the same as you then I copy the source code but the salary estimate keeps repeated ,do you have any solution ? Thanks a lot for these videos, they are really helpful.
Awesome concept for a series!
Great Video!!
This is helpful and enlightening. In my certificate program weâ€™ve been using different tools and add ons to do all this. THIS is much more work but a worthwhile endeavor. It will take some time to get up to speed with github and my coding environment. I was doing coding in a different arena 5 years ago. I hope it informs my ds coding environment
**An easy way to select text** @8:52
1. click where the text starts (just place the cursor and click without holding)
2. scroll down to the end of text
3. press and hold Shift then click where the text ends
Ken I'm curious as to why you prefer spyder over jupyter? Just your preferred editor?
This is a game changing playlist. By far one of the most valuable lessons to date. Thank you!
Ken the just scrape the code that scrapes the website so obv bruh
use css selectors to get html and use scrapy to scrape.
Hey Ken! Loved the video as always. 
I'm still in college and I am aspiring to be a data scientist later on. I just had a question that considering my current academic condition (year 2) is it all good if I use the code of other users (giving them proper credit of course) for my projects which I intend to present for securing an internship later on?

As always, truly appreciate your videos. Keep up the good work of helping us!
Thanks alot
Do you have another way of determining the IDE you want to use outside of it being your preference?
He ken ! great series 
When i run the program the data starts fetching but after a few records one more pop up appears and the entire process stops! 
What should i do?
Thank you so much for the video! I followed along. Unfortunately I got the result for Salary all the same values. I am from the USA. I checked Inspect section, made sure that it's still "gray salary". Any ideas how I can fix it?
hi thank you and keep doing this amazing job and i have question i was doing the same like you but i have problem is spider give this message module not found error can you help me thank yoou
Downloading ipynb from github as py file -

Loading Public Notebooks Directly from GitHub in google colab:
https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb#scrollTo=K-NVg7RjyeTk

From colab you can then just download the ipynb file as py file... Saves a lot of hassles.
guys this error message is hard to crack. help please
ElementClickInterceptedException: Message: element click intercepted: Element <li class="jl react-job-listing gdGrid selected" data-id="3606797381" data-emp-id="1309610" data-is-organic-job="false" data-ad-order-id="1060438" data-sgoc-id="1019" data-is-easy-apply="false" data-normalize-job-title="Data Scientist" data-job-loc="San Francisco, CA" data-job-loc-id="1147401" data-job-loc-type="C" data-njslv="false" style="">...</li> is not clickable at point (216, 248). Other element would receive the click: <div class="background-overlay" aria-label="Background Overlay"></div>
  (Session info: chrome=84.0.4147.105)
hey where can i get raw data, which you scraped
Hi , There  :
is it needed to know selenium ??
Hey, great series! I am not able to fetch salary data in glassdoor of my country. It's not showing there, can you suggest a way around. Th
I know we didn't sign any contract lol , but it is a big honor being your student , i'm learning so much from you , thank you so much !
Hi ken, I got problem after execute the code. it said that 'x out failed'. can u suggest me what's wrong with my code?
i have problem with glassdoor_scrapper module. it said that there is no module in there. what should i do about that?
Hey Ken!

I am facing a problem while importing glassdoor_scraper. Hope to hear a solution from you about it.
hey, ken I'm facing trouble regarding salary, all the salaries in the data frame are the same as the first one, can u help?
Hey, Ken why you prefer spyder than Jupiter notebook...which one I should go for? any suggestions!
Anyone encountered the  ElementClickInterceptedException: Message: element click intercepted: Element <div class="tab" data-test="tab" data-tab-type="overview">...</div> is not clickable at point (547, 475). Other element would receive the click: <p id="onetrust-policy-text">...</p>
  (Session info: chrome=83.0.4103.116) ?
Great video Ken!!
*Solution to the error messages*
I made these two changes to the scraper file and now it runs all OK.

1. JOB button:
Replaced job_button.click() with 
driver.execute_script("arguments[0].click();", job_button)


2. NEXT button:
Replaced  driver.find_element_by_xpath('.//li[@class="next"]//a').click() with
next_button=driver.find_element_by_xpath('.//li[@class="next"]//a');
driver.execute_script("arguments[0].click();", next_button)
When I also put the Job title keyword as "Data Scientist", and run the program, the glassdoor Job search bar only shows first 5 character as "datas". Can't seem to understand why this is happening? I have also tried with the other keywords like Analyst -  even here it  just shows first 5 character as Analy. Can you help why this is happening?
selenium.common.exceptions.ElementNotInteractableException: Message: element not interactable: element has zero size  (Session info: chrome=83.0.4103.116)


I am getting this error every time I run this model.
Thank you for making these excellent series, very well structured!
Thank you so much for this series, it's really helpful for beginners like me. I have a question though, I followed almost exactly how you revised the codes, the only difference is probably that I am using data from both Canada and USA, and the "salary estimate" column shows all identical values (e.g. CA$89K-CA$100K (Glassdoor Est.)) but all the other columns (e.g. rating, company name) are just fine. This is so confusing to me since the codes formats for reading "estimate salary" and "rating" are the same. Any insights you can share why this occurs? Thank you so much.
Thank you Ken for such a wonderful tutorial, it was easy to follow and simple for a beginner to keep up with. I have been scraping Data Science jobs in Canada and they are less than 1000. My num_jobs variable is 1000. So, what is happening is when the scraper reached the last page on glassdoor it is going in a loop and collecting data from the same 5 jobs over and over, I guess it will do that till the length of jobs dictionary reached 1000. What can I do to make it stop once there are no new jobs?
Thanks for the great video! Just out of curiosity, is it illegal to scrape data online with selenium and BeautifulSoup for a project?
Ken, you are the G.O.A.T. 
I recently started to learn python and its application in data analysis, but I was struggling with getting the data in the first place.
This series is awesome! keep up your good work
Thank you veryy much for such an amazing project!! You have covered end to end of this project and it is very very helpful for beginners like me! Thank you so much ðŸ˜Š
Why this is so fun to watch :D
****Solution to one of the problem that I ran to ****
Error :  ElementNotInteractableException: element not interactable: element has zero size (Session info: chrome=83.0.4103.97)

Just replace the line 
job_button.click()  #You might  [ Line number around 63 ]
with
driver.execute_script("arguments[0].click();", job_button)

I just scraped my 1000 job posts without this nagging error. 
Cheers !!!
You can easily select and copy code on GitHub by clicking 'Raw' when you view the file, then press CTRL+A and CTRL+C to select and copy it before pressing CTRL+V to paste it into your editor.
Thanks a lot for this Ken, loving the raw approach!!
Also you could've just downloaded the Jupiter notebook as a .py file. 
Looking forward to this.
Cheers!
Ken Jee thank you for this video. Iâ€™m just. Beginner and while Iâ€™m trying to run the code I keep getting the following error even though selenium is already installed.

ModuleNotFoundError: no module named â€˜seleniumâ€™

I tried manually installing selenium by unpacking the taz file, still the error is there. What has gone wrong?
How do we know when to stop.the scraper
Do we actually need to know the purpose of each line  of copied Selenium code or we can just copy and paste it as it is ?
thank you Ken
HI Ken I am getting X out failed ,while scrapping
Hi Ken! I tried to use 'Business Analyst' instead of 'Data Scientist'. When I reached 167/1000, i got this error:

ElementNotInteractableException: element not interactable: element has zero size
  (Session info: chrome=83.0.4103.97)

Do you have any idea how to solve this? Thanks in advance!
selenium module error on python3? please help
Hi Ken! I'm a little late here but I'm getting stuck trying to run the initial web scraper and getting the following error after printing 'Progress: 0/15'

ElementClickInterceptedException: Message: element click intercepted: Element <li class="jl react-job-listing gdGrid selected" data-id="3343053790" data-emp-id="1309610" data-is-organic-job="false" data-ad-order-id="919804" data-sgoc-id="1019" data-is-easy-apply="false" data-normalize-job-title="Data Scientist" data-job-loc="San Francisco, CA" data-job-loc-id="1147401" data-job-loc-type="C" data-njslv="false" style="">...</li> is not clickable at point (216, 292). Other element would receive the click: <div class="background-overlay" aria-label="Background Overlay"></div>
  (Session info: chrome=83.0.4103.61)

What seems to be happening (based on the message and looking at the screen as it attempts to scrape) is that the code is either not properly able to exit from the 'Sign Up' pop-up or maybe it's not able to click on a posting. 

I've been scratching my head at this for a while now and I'm really stuck. I'm using your code now directly from your GitHub. Anything you recommend trying? I love this series and am finding it very helpful but would love to follow along.
It could be better to just download the notebook and convert it to .py https://stackoverflow.com/questions/17077494/how-do-i-convert-a-ipython-notebook-into-a-python-file-via-commandline
Just cause you asked :  There is a suggestion - Why did you not select raw format and copy from there ?
Am new to the DS environment and the setting up of the repo and all had already overwhelm me.  And the nitty gritty details to amend the code.  Hope I am able to digest and pick up as I continue my upskilling
Hi Ken! What keyboard shortcut did you click to run the program at 20:29 where it showed the Chrome browser opening?
Hi Ken! I love all your tutorials but in this one I am facing some problems. I keep getting the error 'ModuleNotFoundError: No module named 'selenium' ' on the console.
Hey Ken, I'm getting the following error when I run the file : 
ElementNotInteractableException: element not interactable: element has zero size
  (Session info: chrome=83.0.4103.61)
Can you suggest a solution please?
First of all, thank you for your great content. Beautifully explained. I came across an issue, when I run data_collection.py after progress 44/1000, it shows the following errors:
selenium.common.exceptions.ElementNotInteractableException: Message: element not interactable: element has zero size
  (Session info: chrome=83.0.4103.61)
Can you please help. I tried slack but still stuck. 
Thank you again for your content. 
Really appreciated !!!
Thank you very much. The way you faced and solved the bugs is unique and inspirational. Some other videos out there are too well-prepared, which is easy to delude people into the perfectness of the code. Consequently, if the code somehow does not run, people don't know how to solve. Please keep this style.
I am not sure if this is legal cause the robots.txt file at LinkedIn disallows everything on jobs. Mostly every useful data to scrap is disallowed.
For other people - if you have the remote URL permission problem(?) with SSH (26:35), this website could help you. https://help.github.com/en/github/using-git/changing-a-remotes-url
I got the same Salary Estimate values from start to end... I don't know why and it's really a pain in the ass
Thank you so much for posting! I am learning so much, especially what I don't know. and need to learn for my current data project. I'm changing my career to be a data scientist (well aiming for data analyst for now and I'll build up more skills to transfer to data science). It's quite exciting!
Hey Ken, really appreciate your effort.  
I am facing a problem though. Since, i am an Indian user, the website is being redirected to Indian version of the web page and Indian version lacks salary on top where company name, position and location is mentioned. 
What can i do to solve this? 

p.s: Also, while redirecting it gives an option to undo it, but as soon as undo it, the scrapping process gets terminated with an error KeyboardInterrupt.
I don't usually comment on youtube videos, but this series is simply amazing! It's often difficult to find content on data cleaning and model production, so this project series will benefit me a ton. Quick question- what is the best way to go about modifying the scraper so that it can scrape a much larger dataset (i.e. 5000 or 10000 data points)?
It seems my web scraper isn't scrolling down to access new postings.  It will successfully scrape the first handful (up to 15) and then spit out this error:
ElementNotInteractableException: element not interactable: element has zero size

The error appears to be coming from line 61:  job_button.click() 
Does anyone know how to deal with this?  I am new to web scraping.

Thanks!
You can copy the entire code from Jupiter Notebook by clicking, holding, and scrolling. :)
Hi Ken,
I started web scraping and made necessary changes to retrieve estimate_salary as Described in the video, but I failed. By the way, you have inspired a lot to me man, thank you so much. Keep posting great content, very excited for upcoming content.
I was using the jupyter notebook on Mozilla and Iâ€™m getting the driver error again and again. I tried to fix it but it shows unicodeescape error
The text small and hard to see.
Hi Ken, we're you able to scrape the 1000 jobs in one shot,  because I kept getting an error of 'element click intercepted' after the script went through a few job posts. And I googled the world and couldn't find what that error meant. Thanks for your videos they're great.
Try to use the "Raw" button if there's one on top of the editor within the page where you want to get the code from
hey man, i'm from Brasil, and i'm starting a project of soccer data analysis. Your videos are realy helping me out! Thank you!
Hi Everyone, can anyone please assist with this error:
StaleElementReferenceException: stale element reference: element is not attached to the page document
  (Session info: chrome=81.0.4044.138)


I don't get this error unless I try to scrape a large number of jobs, which is weird.
I am an absolute beginner. All this years i realised i always learnt the theory first ,the details first but i wanted to try if i can look up into a project and build curiosity and then work on basics. This really helped. Thank you. Regards , mech. Engineer.
Hi Ken Jee, this is great tutorials! thank you so much !! that's what i'm looking for !!
he Ken Jee, thnx 4 the great tutorials! really loving them.. I'm trying to replicate what you did as a way of learning (i'm still in the learning phase of programming), however when i load the page, i get a ' cookie - consent' pop-up! As a result the scraping doesn't continue (however, when i manually press 'accept cookies' it does continue). Do you know a way i can hard code this in python so that when the page opens, it automatically excepts the cookies too?
Hi Ken, thanks for the series! I'm currently at @23.50. Around halfway through running the iterations I'm receiving an error saying the element is not clickable at point (219, 653). Other elements would receive the click: <div class="gdGrid noPad">. Do you know why?
yes I have downloaded chrome driver and saved in same folder. But chrome driver is 32bit and my laptop is 64 bit support. Please help as I'm beginner and I find really interesting your channel.
File "C:\Users\Shukla\Documents\ds_salary_proj\glassdoor_scraper.py", line 13, in get_jobs
    options = webdriver.ChromeOptions()

NameError: name 'webdriver' is not defined




Sir I'm getting this error again and again. Please help me out
File "C:/Users/Shukla/Documents/Glassdoor/start1.py", line 8, in <module>
    import glassdoor_scraper as gs

  File "C:\Users\Shukla\Documents\Glassdoor\glassdoor_scraper.py", line 12
    In [15]:
            ^
SyntaxError: invalid syntax




i am getting this error
Hey Ken,  really good content as always, keep the projects coming! One question, I was trying to run the script and for some reason the Salary fields were all coming in as the same salary estimate (usually the first job that was copied). Any reason why you could see this being the case.
Hi kenn  I tried running the code in Google colab , and have even specified the path of chrome driver in environment variable ,found the following error: 


PS: I have downloaded the latest chrome driver wrt to the chrome update,and have specified the exact path .



FileNotFoundError                         Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/selenium/webdriver/common/service.py in start(self)
     75                                             stderr=self.log_file,
---> 76                                             stdin=PIPE)
     77         except TypeError:

5 frames
FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/projects/chromedriver': 'C:/Users/projects/chromedriver'

During handling of the above exception, another exception occurred:

WebDriverException                        Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/selenium/webdriver/common/service.py in start(self)
     81                 raise WebDriverException(
     82                     "'%s' executable needs to be in PATH. %s" % (
---> 83                         os.path.basename(self.path), self.start_error_message)
     84                 )
     85             elif err.errno == errno.EACCES:

WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home
Hi Ken, I'm receiving this error when I'm trying to run the program at [12:52]:
"File "C:\Users\Niccolo\Documents\ds_salary_proj\executing code.py", line 14, in <module>
    df = gs.get_jobs('data scientist', 15, False, path, 15)

  File "C:\Users\Niccolo\Documents\ds_salary_proj\glassdoor_scraper.py", line 18, in get_jobs
    driver = webdriver.Chrome(executable_path=path, options=options)

  File "C:\Users\Niccolo\anaconda3\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()

  File "C:\Users\Niccolo\anaconda3\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)

  File "C:\Users\Niccolo\anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 104, in __init__
    super(SubprocessPopen, self).__init__(*args, **kwargs)

  File "C:\Users\Niccolo\anaconda3\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)

  File "C:\Users\Niccolo\anaconda3\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)

OSError: [WinError 193] %1 is not a valid Win32 application"     <--------- ERROR

Would you know a possible fix for this? Thanks always for your great content
Hey Ken, really good content, thank you so much. Just wanted to suggest a change, I guess the jobs.append code in the bottom part is supposed to be outside the if condition, by mistake you put it inside. :)
Hi Ken, good video as always.  I was working on this tutorial and the scrap file worked fine yesterday. I tried scrapping more data today however the "glassdoor_scraper.py" file started to return an error every time I run the "data_collection.py" file. Perhaps glassdoor made changes on their website. I tried cloning your project from Github and it gave the same error. Could you look into this?


Error:


ElementClickInterceptedException: element click intercepted: Element <li class="jl react-job-listing gdGrid " data-id="2952230826" data-emp-id="1405209" data-is-organic-job="true" data-ad-order-id="894020" data-sgoc-id="1007" data-is-easy-apply="true" data-normalize-job-title="Electrical Designer" data-job-loc="Middletown, PA" data-job-loc-id="1152197" data-job-loc-type="C" data-njslv="false">...</li> is not clickable at point (217, 869). Other element would receive the click: <div class="gdGrid noPad">...</div>
  (Session info: chrome=81.0.4044.92)


Thanks Ken!
Hi! What text editor do you use for Git? Vim
Thanks!! Subscribed
followed this through and get an error - TypeError: get_jobs() missing 2 required positional arguments: 'path' and 'slp_time'. not clear i have these variables set properly. thanks.
Hi Ken,
I really like the Video and looking forward to this series. One question i want to ask you is that can i add this project to my resume.
Please reply back to my question.
You're a star. This is a great eye-opener.
Hey Ken,
The Data Science project series is amazing and much needed.
Quick question: Just like we used 'keyword' for searching with job title, what would be the change in code if location too needs a keyword search?
Awesome vid
Hello is very good your channel, is possible get some remote job of data science or data analisis
Can we use web scrapping tool like (parsehub) for data collection?
thank you for the video! one question though: say this came up during an interview and I was tasked with making a scraper. Would it be OK to say to use someone else's code and provide credit for it? look forward to seeing this entire series as I'm currently in my own project-building phase for my data scientist career transition.
This is my first comment on youtube since I am using computer/Internet and It's for you Ken. You have started such a great super awesome series ( Data Science Project from Scratch ) that most of youtubers have'nt and I love it. You are such a great man.  Your Videos are very informative. I believe this series will give your channel more and more subscribers.
Loving this series! Really enjoyed this "buying ingredients" process! :p
There's nothing quite like a video that shows the raw process and is practical! Thanks a ton Ken, looking forward to the rest of the series--especially the data cleaning!
I would think that a database containing the relevant data would exist and then we could see some SQL action
Hi, Ken! Is it possible to use ipad when doing data science? Thank you!
Hey Everyone - I hope you enjoyed the video! Stay tuned for Part 3: Data Cleaning that will be coming out on Wednesday 4/8. I am loving the questions and comments so far, so please keep them coming!
I loved the video.
Happy that I have found your announcement on reddit, looking forward for the next episode.
Amazing series, very well structured! Can't wait to see more!
Do you prefer to learn data science in R or python? Very informative video, canâ€™t wait for part 3!
Great work flow example. Keep up the good work!
Great video, thanks again. I'm curious, you found pre-existing code and made edits to it as you went along. How often is this the case for you on the job or for any other data scientist? How prepared should one be to make their own data scraper? Is that something that we will bump into a lot in the future?
Dope screen
Finally  :D
Part 4 on exploratory data analysis is coming out this Friday! If you haven't seen part 1&2 they are neatly packaged in this playlist: https://www.youtube.com/watch?v=MpF9HENQjDo&list=PL2zq7klxX5ASFejJj80ob9ZAnBHdz5O1t. Would love any feedback on this video and series in the comments section below!
You explained good but while u cleaning data for Excel you have used same AWS variable instead of Excel
thank you so much MR KEN ðŸ˜
â¤
This guy is making journey of struggle fun which is hardest thing to do
guys, my spyder python 3.9 cannot detect any file. it does not detect any file(on the right upper side in this videos) which it should according to this video. help.
can we use anaconda python (jupyter notebook) for this process also?
This is great stuff! I really like how you use the apply method for pretty much everything... makes me wonder why I (and others) bother to memorize a bunch of pd methods, when all you really need is to knowing how to correctly apply the "apply method".
why vdo quality is poor i am unable to see the words, is this only at my side?
thanks for this informative videos
For searching for R in the Job Description, I believe you can search for " R " (with spaces), correct?
lambda x: 1 if ' R ' in x else 0

That would prevent every "r" in a word from the column and count.
Thanks Ken .  it's helpful lost in my daily work.
Really loved the process, Ken you are a painkiller!
Thanks for what you have done so far, it really helped.
11:00-Important
33:00-
Excellent video as always Ken ! Just a small query - when you simply removed the 'per hour' from the salary text, wouldn't it have been worthwhile to multiply the min and max salary by the avg. number of working hours in a year, because the other salaries are also given annually, presumably? (since the timeframe of all salaries need to be equal)
This have been an amazing tutorial about "exactly what i was looking for", thank so much, for showing all this process!
Thank you for this great video. Learned some good stuff. I perticularly learned git in the last and this video.
This is gold, thank you! Ciao from Italy
Nice processðŸ‘
Ken Jee this is Great Stuff
instead of dropping an "Unnamed: 0" column, we can pass the "index_col = 0" argument in the first place when we define the df variable as our dataFrame variable.

maybe looks like this
df = pd.read_csv('glassdoor_jobs.csv', index_col=0)

the documentation says "index_col=False can be used to force pandas to not use the first column as the index,"

correct me if i'm wrong. 

hey by the way, what a nice playlist, i enjoyed it. thanks ken, big thumbs up
Somebody might have commented already, but in more recent data pulls some salaries are more precise thus they don't have a range so edited the lambda for max salary checking len(x.split('-') first to avoid out of range errors
Hi, I am entering into the Data Science world and I have an easy question:

 I am using Sublime Text and not Spider. When I plot my dataframe there (df = pd.read_csv('glassdoor_jobs.csv'; print(df)) I do not get a terminal where I can explore the whole data (like Ken does). Instead what I get is the df cut off. I can explore it by using some commands like ".head(20)/.tail(20)/etc..." and specifying the columns that I want to be shown, but it's kind of annoying and you may not find some variables that need to be cleaned by doing that.

Does anyone know what could I do to display the whole dataframe outside Sublime Text to explore it? 

Ty very much!
This is outstanding content. Watching this series before I have started on a project will save me so much time.
Amazing set of videos! Thanks for all these hard work! As data scientist yourself I believe you don't need the income from these videos but just love sharing knowledge, greatly appreciated ðŸ‘
very helpful!Thank u for making this vedio.
Hi Ken, I first want to say following these vids has been amazing so far.

Quick Question, sometimes I get the following error: 
StaleElementReferenceException: stale element reference: element is not attached to the page document

I think It may have something to do with my internet connection, because it happens randomly during the scraping process.

I guess the question is does the file have to feature 1000 entries? I think working with a smaller data pool might prevent the random error. Will something like 500 or even 250 work?
I am absolutely LOVING this series! I've been studying for a while and always wondered how an actual data scientist would use all these tools on an actual project. Great work Ken! Just found your channel today and I have a feeling I'll go through your videos really fast
I really shouldnâ€™t have laughed at 30:16 when Kenâ€™s like â€œyea sorry about the sirens. You know, tough times out thereâ€. But itâ€™s nice comical relief when youâ€™re slogging through code like that. Ken you do a GREAT job at explaining the process end to end! I love this mini-series.
If you could increase the font size of your codes.
That would be very great!!
Thank you!
What IDE is he using?
Thank you Ken for this Amazing content!
Very helpful, thanks
Hi Ken jee...  How are you ?..can u please tell me .. in this playlist from where to where a data analyst part(i want to learn to fit in data analyst position )... Thanks for your efforts...
Hi in python code :df["Age"]= df.Founded.apply( lambda x: x if x<1 else 2020 - x ) , -1 will still present in new column Age?
I luv u Ken u teach me so much
yeap !! i was stuck on parsing!! you made it soo clear! THANK YOU KENN
Warning Read This Message Carefully
Maybe you are good in data scinece field maybe you are a good teacher but when you teach us we can not see properly your coding so you should zoom your content and one of your friend which channel name code basics who is greate video creator and he is your friend so he can help you to making good video editing like he is do.
love you brother â¤
Thanks for the video Ken. I have a question on saving the datafile after the cleaning process.  Though not applicable in this video--when I clean up dates and some string fields--saving as .csv loses all those changes. Then the beginning of my EDA is doing that cleanup for the fields the csv does not save. Is this normal? Am I missing something? Appreciate the help. Be well.
lamba function is actually quite useful! damn.
Hey ! Can you tell how you scraped the csv file of glassdoor . It would help a lot. I'm complete new to it, so have no idea. Thanks !
This series is amazing! But in 33:55 it would be nice if you had also checked which jobs are asking for Masters degree, or asking for X years of experience
Thanks so much Ken. 
Learning a lot from your mini series. I do understand and appreciate the time and energy commitment and surely hope you shall continue the series.
You have ended the hate I have had for Lambda functions (just because I couldn't understand them) in the first 20 mins of the video. Thank you!
Thank you so much Ken, please keep it up.
That was very helpful, I got a small question when you clean the salary why not change the hourly to a year salary?
Hi ken, at 37:44 when you are trying to parse the job description, for that excel job, it seems you forgot to change the function that count the jobs, you took aws as it is.. ðŸ˜… and finally thanks for this whole Data Science project series.
For the cleaning, can I use Excel as well and then save as .CSV and load back into the   code?
btw the output console at 29:00 shows that Los Angeles is counted as a state(but it's not)
Great video, thanks so much! I noticed that if you use '  r  ' (whitespace on each side of the r) you get some of the r results that otherwise would have been missed by only using 'r studio' and 'r-studio' in the lambda function
Hi Ken, i just started this series and i am at 23:44 as of the time writing this comment. i think you mixed the hourly and annual salary which can skew your data.

e.g. $28/hour = ~58K p.a. (40h/week, 52 weeks)

since you replaced $ and K you will use the 28 for your average calculation instead of the 58.

But since you marked them in the additional column im sure that you adress this issue in the video.
Found your chanel these days and cannot wait to code this project over christmas holidays and learn a lot along the way. This looks like a very quality series! Great content! I especially like that we see the whole iterative process of a project and the googling and looking things up and everything. Very nice :)
This is actually so good for me understand the concept while you are doing the project and also I think maybe cause of dark mode I am not able to see properly on my mobile I will try watching somewhere else but other than this series is worth it 
I hope you make a new series of project with another ideaðŸ’¯ðŸ˜ŠðŸ‘
ðŸ™ðŸ¼
Great job again. As people already mentioned, uploading the video without editing enable us to understand the process and be more confident that "trial and error" is part of the process.

Also, you should add a highlight to that moment when you checked the company foundation date, this is a really important sanity check.

Obs. Apply seems amazing. I write a lot of bad code to do the cleaning, it is embarrassing haha
Man, this series you made is the most important video in my learning by far. Thanks to you I realize I'm already can start building projects and work more on my portfolio. I was always thinking I'm not ready enough but with your series, I realize that I know what to do. I can't say how much your series had helped me. Thank you!
thanks ken, really appreciate the effort in these vids 

i faced an issue with the state split 
[
df['job_state'] = df['Location'].apply(lambda x: x.split(',')[1])
Traceback (most recent call last):

  File "<ipython-input-32-5c1b9e64688a>", line 1, in <module>
    df['job_state'] = df['Location'].apply(lambda x: x.split(',')[1])

  File "C:\Users\itxab\anaconda3\lib\site-packages\pandas\core\series.py", line 4200, in apply
    mapped = lib.map_infer(values, f, convert=convert_dtype)

  File "pandas\_libs\lib.pyx", line 2402, in pandas._libs.lib.map_infer

  File "<ipython-input-32-5c1b9e64688a>", line 1, in <lambda>
    df['job_state'] = df['Location'].apply(lambda x: x.split(',')[1])

IndexError: list index out of range
]

says index out of range although i splitted on comma so if any1 faces the same issue i would recommend doing what i did 
replace 
df['job_state'] = df['Location'].apply(lambda x: x.split(',')[1])
with
df['job_state']= df.apply(lambda x: x['Location'][-2:], axis=1)
we took -2 as all the states are 2 characters at the end
within the dataset there are some observations preappended with 'salary:' so int() is throwing an error at this point of getting the min & max salaries. to get that out of the way.i did this: minus_hr = minus_hr.apply(lambda x: x.split(':')[1] if 'salary' in x.lower() else x)
Wow, I love these series! Very helpful and inspiring
This guy is amazing!
Hi Ken!
Great video and value, I learned alot. I have one question:
Why did you make a separate column for "Employer provided salary"? It makes sense to me to simply remove it from text and treat it as regular salary. What is your opinion on this?
i like the series but zoom in required for videos
This is just amazing Ken ! now I know that's the kind of job I wanna do for a living :) thank you so much for sharing !
Lmao! U have good quality. Freshers like us should follow ur style.ðŸ˜œ
Hey Ken,  

Not sure what you're reasoning or purpose of creating your Youtube videos are, but you've been an inspiration towards me, and if you get down or whatever, just know that you've helped me alot.
what a clear explanation man, hats off..:)
i'm already equipped with basic python knowledge,  how do i begin Data Science
Hi Ken, I am not able perform below code in python 3 - giving me error
df['min_salary'] = min_hr.apply(lambda x: int(x.split('-')[0]))
When I am using [1] then it's giving me max value but not min with [0]
Thanks for all the effort you put in Ken. It takes a lot of effort and time in making these videos which will help you and as well as the community.

I had enormous interest towards sports and I do want to contribute to the field .However I came across your videos and i really like the way those videos were organised.Keep your good work mate
Excellent. this is very helpful.
In 37:40 ish , you copied the code from above and edit for the excel function, but u forgot to edit the value count which is still 'aws' count so you said 'surprisingly data are the same.' :D . Needless to say , your whole video is Great. :D
Hi Ken. Really it was a great video on the data cleaning process. as a data science beginner i was really finding the data cleaning part extremely irritating when it tried it on some of the beginner projects that you have recommended. but after watching this video it would certainly help me a lot to practice more on data cleaning process.
Thank you for this amazing content! At 37:50, you looked at the value counts for aws not Excel. Line 58 says 'df.aws.value_counts()' when it should say 'df.excel.value_counts()'
i can't understand how you removed glassdoor est. with just split('(')[0]). I'm confused. please explain bro.
I love your commitment towards teaching 
replying and liking each and every comment is not so easy 
but that's what making you special 
keep growing and keep sharing knowledge 
I hope one day you will reach your expectations 
thank you alooootttt
Hello Ken, I was able to scrape 1000 jobs from glassdoor but I noticed all the salary estimates are the same (58-90k). Please what could be wrong?
First went through a couple of minutes of the video where you discussed what had to be done and started solving it by my own. Once I was done, came back here to check out how you'd solved. This was immensely helpful as my code was not as efficient, and learnt better approaches to the same problem! Thanks Ken!
values_count you used for excel is 'aws' copy and paste/editing error (37:40) I think you meant to say df.excel.values_count( ). Otherwise lambda made simple here. Please could  you do videos on lambda? Otherwise great video as always. so much to pick up Thank you!
impressive work so much to learn thanks for doing this Ken keep up the hard work!
Hi Ken... This is really very informative, for me as a newbie in DS. Glad to see that as comfortable as you are using the lambda instead of RegEx with this one to clean up data, yet had to google how to drop a column. :)  I thought that was very cool that you didn't edit it out and makes me feel better. Very encouraging... keep up! Thanks a lot for sharing.
Been following this channel since I got let go after COVID 19 budget cuts, but figured I'd try to turn something bad into a good opportunity and use this time to learn data science, but this series is awesome coz it really ties in all the theoretical pieces from the coursework together. thank you! Around 26:15, Ken u said we didn't specify a series and we have to let the dataframe know we're doing this on rows....- I don't get this, what does axis = 1 do??
These videos are incredibly helpful man. Thanks a ton from an inspiring data scientist!!!!!!!
Hi Ken, I've been following your work quite some time now. The way you keep your online presence is inspirational. I would love it if you have more step-by-step project videos on Youtube. There are so many areas in which I don't even know if analytics are applied. Sport analytics is interesting for me for example. Also, projects with more practical implications like the regular churn model or HR analytics would add value to your channel, too. I would enjoy watching them on my end at least.
Just a piece of suggestion on selecting keywords from job description, use "for loop" will make it better organized and easier to add new keywords, and the new added columns will always have the same suffix "_yn", to avoid unnecessary inconsistencies.

skills = ['python','sql','excel','aws','spark','nlp','rstudio']
for skill in skills:
    df[skill + '_yn'] = df['Job Description'].apply(lambda x: 1 if skill in x.lower() else 0)
Thank you for the work Ken, the idea of showing everything step by step is very helpful for beginners. It's boring indeed but no one can get stuff done without the boring phase. I really like the IDE you are using here, with a variable window on the top right, very easy to click on and check out each new variable created, is this Spyder? I am using Pycharm and Jupyter notebook, and didn't find similar features from them, do you know if there is a way in Jupyter notebook to show table contents in a separate window? right now I just use "df.head()" to check, thank you so much.
Thank you. the tutorials are very crisp and interesting. Favorite series for sure.
Excelent video!!
hey ken! i hope you are fine. stay home, stay safe. i would like to give suggestions to
make videos on
1)-data visualiztion
2)- real time projects of data science 
3)- contest going on kaggle and teach how to solve them.
4)- just do not stop making these wonderful videos on data science, it is very helpful for newbie in data science. 

All the best!!
I also love the background music. Can you tell me where can I find it?
Thank you for your playlist! It's really helpful
Yeah, this series is super useful for beginners like me. Thanks for making this.
I really like this series and I really learned a lot. I am also reaching out to you for a project Idea, I am a data engineer. Please help me
A good series explaining the data science process which a lot of videos and articles ignore. This video in particular would be the time to mention using existing and/or creating a codebook for the dataset.
Fist of all, thank you for your time making this series. 
It casted a lot of light to me on the big scheme of things in a  project (how you handle it as a whole) Most resources deal just with certain parts so they miss the big picture.

I'm having a hard time...  
I'm trying to get ready a data set (cleaning, inputing, binning, etc)... i wrote individual functions that take the full dataframe as input and outputs it with the respective transformation/inputation/...
Resources mention that is good practice to write functions... So i did... Then i stumble across custom transformers, now I'm trying to create one to use it rather than the individual functions


What is the difference between using lambda funcitons( like in here) and creating the custom transfomers?

Is it good to write one transformer that will deal with all the steps (cleaning, custom value inputing, changing types of values, discretizing, aggregating categories, etc, etc)  to get my dataset ready?
Or what am i supposed to do?
Then i would like to use it in a pipeline to finish with encoding and scaling...

I'm kinda lost and can't find any good resource to solve this...

Thank so much you and keep the good work!
Thank you so much Ken. It is very helpful.
If anyone getting error at 21:55 when Ken tries to convert it into int.
I tried this method and it worked for me:
df['min salary'] = pd.to_numeric(df['min salary'], errors='coerce')
df['max salary'] = pd.to_numeric(df['max salary'], errors='coerce')
df['min salary'] = df['min salary'].fillna(0).astype('int64')
df['max salary'] = df['max salary'].fillna(0).astype('int64')
After This Data Type Will be Changed From Object to int64.
You can also check  Data Types of every single Column in your DataSet using
df.info()
Or
df.dtypes
In Jupyter NoteBook
Very good tutorial. I love the way you explain things. It's easy to understand! ^_^
If we follow all these videos step-by-step, could this count as a project to put on a resume or LinkedIn?
appreciated for your  excellent and exceptional work! As a suggestion the videos are a bit long it would be much better if you split them into like scraping data, data cleaning, etc. Hard to see some of the codes on big screen maybe consider using Jupyter Notebook or changing the font or background colour Thank you for your all hard work!
Great series. I'm trying it out after looking at your video. I feel that the per hour salary is just for an hour. While you have replaced the per hour with a blank. Aren't we gonna convert the per hour to the actual salary. By googling I found out that a data scientist in the US works almost 60 hours. Shouldn't we multiply this with the per hour salary and then with 52?
Is it possible to see the data frame as you are in the top right corner (similar to how it's presented in R) in PyCharm or is this view specific to your IDE?
This series is exactly what I wanted and I highly recommend to anyone who is entering in Data Science.
Hi Ken, what is your opinion of writing Unit test to make sure your data cleaning is done correctly? It is hard to find a mistake when you have thousands of rows. But you can find mistakes better if you data set is small and controlled.
I used to Hate Lambda function , but really I got  good understanding from this Video ,
Thank you so Much
Was nice to see near the end of the video that even you too had to look something up! Further backed up your video saying that no real data scientist memorizes everything. We appreciate you for all that your doing!
Hi Ken! I am an italian master's degree student in computer science, and this kind of videos are pure gold! I have a question: since I'm currently attending classes, are there ways to work on projects of this type, let's say "freelance"?
I would like to start making a bit of money but without affecting the lessons, thanks!
Hi Ken. When you did the search for excel, you forgot to change df.aws to df.excel which is why you got the exact same count.
I tried using lambda functions the way u are using to mark as 1 if data have 'developer' But i am getting error.
TypeError: argument of type 'float' is not iterable
a['developer']=a['MainBranch'].apply(lambda x : 1 if 'developer' in x else 0)
Main branch contains statements something like below
Ex : I am a developer by profession , I am student, I am working as a hobby.


Please let me know what mistake I am doing.
Hi Ken. Thank you so much for this series. This series is such a huge boost for people like me who are trying to learn data science on their own. I have a question regarding the data cleaning. In the video, you manually scrolled through the data to find odd values such as 'per hour', 'employer provided salary' etc. in the Salary Estimate column. But how would you find that kind of value when the data frame has hundreds of thousands or millions of rows? Is there any function or way to find those odd data without manually scrolling or searching?
Excellent work, Ken. Your 'soup to nuts' approach is extremely helpful to those like me who are brand new to data science. On top of everything, I like how you show us your use of Git and GitHub as well as all of the lambda functions. Keep it up!
I still don't have enough experience in using python but am amazed in all the "magic' that it can do! Great job, Ken! You're amazing! :)
In my case , i change three line of code in glassdoor_scraper.py:
job_buttons = driver.find_elements_by_class_name("jl") #the loop interupter in 12 iterarions.
for
job_buttons = driver.find_elements_by_class_name("jobContainer") #solved
and data_Cleaning.py 
df['job_state'] = df['Location'].apply(lambda x: x.split(',')[1]) #undifined position 
for
 df['job_state'] = df['Location'].apply(lambda x: x.split(",")[1] if  len(x.split(",")) == 2 else x.split(",")[0]) #solved
and 
df_out = df.drop(['Job Title'], axis = 1) #in windows, excel the firts column no is 'Unname'
for 
df_out = df.drop([], axis = 0)  #Solved
In my case, replace in data_Cleaning.py this line:
df['job_state'] = df['Location'].apply(lambda x: x.split(",")[1]) #list index out of range
for
#Solved list index out of range in case on the city does no have ","

 df['job_state'] = df['Location'].apply(lambda x: x.split(",")[1] if  len(x.split(",")) == 2 else x.split(",")[0]) 
# se soluciona problema de fuera de indice, cuando se presenten ciudades sin siglas.
Incredible video series. Thanks a lot for this info, no one did videos projects like this. I will follow closely each one and please make more series like this. Thanks and  already subscribed to the channel!!
Thanks a lot for your well-detailed videos! Massive help.
Hey ken the reason why excel has the same count as aws is because after you did the lamda for excel you didnâ€™t replace aws to excel to count
Great work man! Thanks a lot
Hey Ken,
Is it just me that I'm unable to see the salary component on the left-aligned job summary columns. I'm able to see only 1. Company Name, 2. Job Title, 3. Location. Is the Salary estimate not visible on the updated Glassdoor page?
I got '-1' as salary estimate for all jobs.Â And this is the same URL from Omer Sakariya's code.
URL = https://www.glassdoor.co.in/Job/san-francisco-data-scientist-jobs-SRCH_IL.0,13_IC1147401_KO14,28.htm?locKeyword=San%20Francisco,%20CA&seniorityType=all&applicationType=0&locT=C&remoteWorkType=0&fromAge=-1&minRating=0.0&minSalary=0&cityId=-1&employerSizes=0&industryId=-1&companyId=-1&sc.keyword=data+scientist&includeNoSalaryJobs=true&jobType=all&radius=100&locId=1147401&sgocId=-1&countryRedirect=trueÂ 

From the "Part 2" tutorial, the salary estimate was available in the short summarized segment of the Glassdoor pages.
Now the 'Salary' is visible at the different experience levels (Trainee/ Junior/ Senior roles) which becomes tedious to extract and clean.
Awesome video. Is this project resume worthy?
Great examples! I really like the content you are providing ðŸ‘ŒðŸ» but Iâ€™m wondering, how much of the statistics you learned while studying are you applying on a regular basis?
these have been enormously helpful. i've been watching a lot of videos not necessarily acting just yet. btw when the weather gets warmer are you going to be wearing tank tops in your vids?
Data cleaning process is a very important step and can be very tough at times depending on how messy our dataset is. Thanks for the detailed video Ken!
Things every Data science beginner needed.
Thanks Man. Keep it up :)
Hello Ken ðŸ‘‹ I am interested in making a project with a deep learning algorithm. Could you suggest me a good deep learning algorithm to work on. Thanks.
Edit: the project will be for my CV
I really like that you don't edit things out. I think the process is much more informational than just the result. This is a good mini-series man, keep it up!
Loving this series, definitely going to take notes on these videos , so I have steps and a nice framework to follow when I put together my own data science project. Currently trying to build out my portfolio in order to get a job, I have been doing some follow-along tutorials to familiarize myself with some technologies I would like to learn : python (pandas,scikit-learn, tensor flow) , pyspark, and then Airflow. Eventually I would like to create an end-to-end project using a combination of these technologies. Keep the videos coming man! Thanks!
Alternate title: "Part 3 (Lots of lambda functions)" haha! Great video Ken, really enjoyed the on-the-spot feature engineering
I'm a DS Major and this is very helpful. I can see your channel blowing up when all the software engineers are switching over to DS! lol
Part 4 on exploratory data analysis is coming out this Friday! If you haven't seen part 1&2 they are neatly packaged in this playlist: https://www.youtube.com/watch?v=MpF9HENQjDo&list=PL2zq7klxX5ASFejJj80ob9ZAnBHdz5O1t. Would love any feedback on this video and series in the comments section below!
A wonderful way to present this sometimes confusing topic. Thank you!
Hello sir ,
 you have created a very interesting video that I have never seen before . And it also help me to grow my own channel # DecodeTheCode thank you so much sir
Hey Everyone! I realized that there was so much information here, that an EDA could have made for a project itself. Please let me know in the comments section if you would be interested in a video where I go through the exact job related findings from the data in this phase!
This is a simple and extensive mode of EDA, really inspiring, am adopting best practices
thanks sir , you are the best
why do some use lambda in apply function vs what you did with the title_simplifier
so informative, I learned a lot
you have to also separate segment of the job description into company description and job description  it is great video love from india
As for somebody who's going to enter the data science field soon these are great tutorials. Thank you!
18:30-Non Graphical Descriptive Analysis 
20:10-Making Histogram
22:10-Making Box Plots
24:30-Correlation Analysis
28:50-Categorical Variable Analysis
Barplots based on count
34:47-Seaborn xlabel Rotations 
45:00-Pivot Tables(pd.pivot_table,sort_values)
i cant able to get why  number  is divided by 1000            13:03   need clarification
Hey ken, you converted min and max salary from hourly to annually by multiplying each value by 2. am cant figure out that makes it annual. please help. around https://youtu.be/QWgg4w1SpJ8?t=1003
Amazing
I loved this work, it helps to imagine and predict the daily problems of a data scientist may face and solve. Thank you highly, appreciate your work!
From where can I get the codes....which u have used in the tutorial
I am learning a lot from this series; real world project based learning. This is what an inexperienced person looks for. I want to see similar projects from you in the future. Also like your unedited videos showing us how you resolve coding errors. Thank you for your time and effort.
you can save a lot of time if you use control+arrow instead of just arrows, allows you to jump to the end/begining of the word
Got lost in between the video, I would definitely finish this playlist then start a relatively common project.
Hi Ken! thank you for the insightful content! I havenâ€™t scrolled through all your videos but I was particularly interested about how to deal with not normal distributed data. You talked about normalisation and I heard that we could instead use other statistical methods to work with skewed data. Did you do that already on another video? And what do you think about Pandas Profiling? Thx again Ken!
a job simp ? eh
Way to go! This was what I was looking for - the actual number jiggling...
Thank you Ken! I liked that you did not edit "stuck" part ... Gives some motivation to a beginner like me. ðŸ˜…
Hey Ken Jee, thanks so much for your videos, I have a confusion which I can't find a valid solution else where. It is regarding outliers.  In real data, outliers can exist in more than half of the features and make analysis challenging. 

Should I remove all outliers? When is the best time (or stage) to remove them?  During data cleaning or after building the very first model for inference?

Thanks!
Very informative playlist ken ....
Can I add till this part as my intern data analyst portfolio along with some modifications
can anyone help me please suppose i want to plot in "which state we have max salary"  how can we do so ?
I have a coding test for a job interview tomorrow where I have to do data cleaning and EDA in python. Your two videos have been very helpful! Thanks Ken
can You provide Us the code that you use in the end ? that gives image representation of all the words??
Amazing job ken thanks for sharing. Beatiful serie keep it up! Will you make any other serie like that??
Should I use Excel for the Pivot Table or Python ?
this video explains how part but it did not 
talk about what and why
Great Series.
In case you are confused with multiplying the hourly rate by 2, here what it happens under the hood: 2000 = 8hrs/day * 5 days/week * 50 weeks.  The year has 52 weeks but 2 of those weeks are assigned to holidays and vacation time.
you are the best brother <3
hey Ken, I am doing my version of this project in R,
I have a question, when I find that Age is not normally distributed and that most of the data set are not old companies
what should I do then regarding analyzing the age? can I still depend on Age and see how Salary changes as a company gets older ?
or this means that there is under representation of the old companies in the data set and I can't draw any conclusions from the Age variable w.r.t the no. of job postings and Salary?
Have you ever did EDA on your own linkdin profile ...I came across this in Linkdin feed where they do eda and make dashboard on your own linkdin  data
This is very intresting because I have been doing EDA for Internship so this helps me a lot and can't wait for next type of project series ðŸ’¯
while scraping the glassdoor website it is redirecting to an Indian website is there any way I can stop it.

can anyone just guide me on how can I rectify it it will be really grateful

I stopped manually but the scrapping results are not convincing, like sometimes I am able to scrap the salary properly sometimes not.
Is there any reason you didnâ€™t Start out with Pandas Profiling just to take a quick scan of the data?
The best thing about this video was watching Ken getting stuck, trying hard to figure out how to resolve the errors and googling the seaborn code. Just made me feel that it is totally okay to not know everything. Thank you Ken :)
thanks for sharing the whole process, including all 'surprises' along the way with error and google searches. Most people this that only geniuses can make it. This helps to "humanize" the data science process haha
Ken, I understand the value of understanding the data you are working with, but could you explicitly tell us what are the outputs you expect from an EDA and how it impacts the outcome of the model and of the project in general?
hey every1 if yall faced an issue with the nltk downloading (namely wordcloud error)  if u dont have the package use this

import nltk

nltk.download()
Hey Ken, I really appreciate this series but I worry about the dependant variable being the 'Glassdoor Estimate' It seems overly possible that any trends that you find in this EDA are properties of the Glassdoor Salary Estimate algo. Anyhow, this is great as a proof of concept. I would love for you to make a 'Data Science from Scratch 2.0' where you tackle a problem in the sports domain, where you are an expert and there is a wealth of real-world data to choose from!
hey ken  , while i am performing my wordcloud code part , i am getting this error "The _imagingft C module is not installed" , what should i do?
for doing this part "#Remove new lines from company text" , run this code 
df['company_txt'] = df.company_txt.apply(lambda x: x.replace('\n', '').replace('\r', ''))
Can u please explain how hourly was annual done? like why we multiplied by 2????????
Greate series!
Complete data noob here. My work uses Excel for data analysis and reporting, etc. Sounds like switching to Python (I'm a CS student so I love it) and Jupyter could be a good move. Is there a lot that can be done with these methods that Excel can't? Assuming the data is already cleaned and ready to analyze
U r the best...simply awesome videos
Aren't you data snooping the test set by doing a train-test split after EDA? Also, great series. Very helpful.
It is very difficult to see your codes, as the screen is so small. please make sure the codes are visible to us.
When do we remove the NaN or null values and outliers in the dataset?
This was such a fascinating video to watch. I think this is my favorite in the series so far and one that i'll be definitely coming back to and making some detailed notes on. Thanks for sharing the wealth of your knowledge :)
What are some benefits to using spyder as opposed to jupyter notebook for your other steps?  or is this just preference?  GREAT videos man, really enjoy all your content.
50:00 to 55:00 
a real data scientist problems 
ðŸ˜…ðŸ˜…ðŸ˜…ðŸ˜…
we cannot figure out the problem even if it is in front of us
I'm using python version 3.8.2 and even after installing wordcloud using pip3, anaconda wouldn't recognise it in the environment. From what I've learnt online after researching I found wordcloud isn't supported for python version 3.7 and above.  What should I do?
Hi Ken, thanks for this awesome series. I'm literally stuck at the end of this tutorial, it looks like stopwords variable isn't really pointing at the Corpusreader object in nltk. I'm getting the error code TypeError: 'WordListCorpusReader' object is not iterable. Any tips?
Hi Ken, just an idea to better extract seniority information, if we could take how many years experience required from the job description, that would be a good indicator. For now a lot of jobs `seniority` is `na`. Just my 2 cents opinion.

Also, do you still accept resume revision request? I've watched your serious of videos on resume and modified mine accordingly, it'd be great if you can take a quick look at it and provide any feedback, thank you so much!
RuntimeWarning: Glyph 13 missing from current font.  Hey Ken getting this error 33:10 help please!
Hey, ken hourly wage to annual what actually it's 17:00 trying to calculate can you please explain?
This playlist is very good.

Best way to learn
Hey Ken,
I am just a beginner and I wasn't able to understand why should the variables follow a normal distribution in order to apply regression?
Loving the content so far, thanks!
Hi Ken, at 58:46, the error is caused by using `avg_salary` to pivot table against `avg_salary`, it can be solved by replacing the code:
for i in df_pivots.columns: 

with

for i in df_pivots.columns[:-1]:
hi sir,
In mu juypter notebooke value_count is not showing signature as value_count() when i press tab button
Hi Ken , Can you just explain that part 13:12  of converting hourly wage to annual. Btw  awesome content !!
hey this content is very useful and interesting , thank you so much. waiting for more such videos... :)
Thank you so much for this video, your channel has by far the most helpful content on data science on YouTube and its not even close. Keep up the great work!
wow, as a newbie, watching you do some cool stuff is so interesting :D. Especially the last part with that WorldCloud. I think it's an amazing package
Hey, for those who get stuck with multiple off 'Location' (i got multiple 'Location being like "los angeles" for Ken Jee).
It's not an optimal code but it does the job :
#Making every names a state abreviation
def state_simplifier(state):
    if  'utah' in state.lower():
        return 'UT'
    elif 'new jersey' in state.lower():
        return 'NJ'
    elif 'greenwood village' in state.lower():
        return 'CO'
    elif 'united state' in state.lower():
        return 'US'
    else :
        return state
df['job_state'] = df.job_state.apply(state_simplifier)
And to get rid of all the space after that i simply used a lambda -> replace : 
#getting rid of the spaces
df['job_state'] = df.job_state.apply(lambda x: x.replace(' ',''))
Hope it can help someone ! Have fun codding !
people, when to pass axis parameter, in DataFrame.apply() function ?
Ken doesnt put it in a few functions and it works, but at 13:45, the program hits an error!?
Thanks A Lot Ken For Your Data Science Project From Scratch Playlist Series. 
Ken Can You Recommend Some Youtube Tutorials OR Blog post where i can learn About All Machine Learning Algorithms. The maths behind them and also to implement them using scikit-learn.
And i am interested in starting freelancing in Data Science/ML.  Can you give some tips on how to start freelancing on upwork/fiverr about Data Science/ML
Thanks In Advance !
Should we have the Knowledge of Natural Language Processing to follow this project??
Hi Ken! am a beginner. I just want to know if this case study can be added in my resume after learning it thoroughly. ???
Thanks for this series, I have always felt intimated by the whole process of data analysis and model building, this series gave me plenty of confidence to step up my efforts in the field and focus more on projects as well. Thanks!

Also what is the font that you're using in Jupyter Lab?
Man, as a newbie I can't thank you enough for this playlist. Helped me wrap loose concepts altogether.
great content Ken... more like a therpy for data science learners, loved the way you exlained while working through
Howâ€™s EDA done for image based problems ?
Great stuff Ken!!! Even though I'm an R guy i still find these types of videos very valuable. It's great to see the actual thought process and methodology. Reminds me of gameplay videos lol
Hello Ken, Is there any that we can connect through WhatsApp? I want to grab more knowledge/ techniques from you because YOU ARE THE BEST. 
Please consider my request and I wont bug you with too many questions in case if we connect.
I basically followed and tried every step while watching the video. It is very practical and useful to learn during job preparation !! One little thing is could you please zoom in the page a bit more next time , especially edited in the dark IDE, so that it is easier to watch and practice the code together. :)
Sorry is this is a dumb question but what are we exactly looking for when we look for trends? Are there some common things that you look for as a data scientist or do you just really need to understand your data well and be creative to find some interesting things in your data? Any resources you suggest for how to go about doing EDA as a beginner?
Hey Ken It's very interesting as  I am beginner it makes me more curious to learn new concepts and I am following all your playlist
I'm watching all the series in a night, perfect for the beginners!! Greetings from Barcelona
in my case for Python 3.8.2 in Windows 10:
*Anaconda prompt in Administrator mode, run this code:
conda install -c conda-forge wordcloud #solved


Or

Download package:
* wordcloudâ€‘1.6.0â€‘cp38â€‘cp38â€‘win_amd64.whl
 from
* https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud 
in Windows cmd  move to folder download and run this script: 
* pip install .\wordcloud-1.6.0-cp38-cp3 #solved
Hi Ken! Your video really inspires me a lot! Keep up the good work and hope I will be as good as you one day! :)))
Hi Ken, a small tip for 35:30, instead of rotating axis labels I usually flip coordinates. It makes all the labels visible and the reader does not have to turn his/her neck to read the label. Great work by the way, really loving the content so far!
What's pre requisite to do a exploratory data analysis? 
Python pandas
May be statistics and?
In my case , i change three line of code in glassdoor_scraper.py:
job_buttons = driver.find_elements_by_class_name("jl") #the loop interupter in 12 iterarions.
for
job_buttons = driver.find_elements_by_class_name("jobContainer") #solved
and data_Cleaning.py 
df['job_state'] = df['Location'].apply(lambda x: x.split(',')[1]) #undifined position 
for
df['job_state'] = df['Location'].apply(lambda x: x.split(',')[0]) #solved
and 
df_out = df.drop(['Job Title'], axis = 1) #in windows, excel the firts column no is 'Unname'
for 
df_out = df.drop([], axis = 0)  #Solved
Good job !!
Great video Ken! This is exactly the motivation I needed to continue my data Science journey. The lockdown has been a morale killer  but your video definitely motivated me to keep learning. 
Thank you!
Hi Ken, Thank you so much for the series and everything you have done so far in this chanel. In case of the series "Data Science Project from Scratch", this is something I was looking for. Practical knowladge, without cutting, with using Google if it's necessary. Definitely, you helped me a lot to sort my knowledge and add some interesting tips. Keep a finger crossed for development of your chanel and if I can say something negative, then... I would rather to have a possibility to give you more thumbs up :D
I loved the compelling data storytelling during your exploratory data analysis phase. I can't wait for part five. Thank you for your effort and value. More grace Sir
Please make a video on complete roadmap to become a data scientist
I think you may benefit from chopping these into 20-30 min sections. I think that's more digestible for the average viewer and you get more bang for your buck as far as time invested vs content goes. Anyways, enjoying the content as always.
Ken Jee upload the video" Like video comment on video, then watch :D
i'm from Tunisia in North africa and i'm very interested to learn data sience for  sport . can you please send me the  books that you used to learn betting and sport anaytics !
this is my email : Salemwisal@gmail.com
thank you!
awesome content!! I don't have time to watch all of it right now, but I definitely will. I am in a data science course right now and the book we use is literally called "Data Science from Scratch"! :)
Hi Everyone - Thanks for watching! I have gotten awesome feedback thus far on this series. Again, my focus here is to show that data science is an iterative process. You will constantly find bugs, errors, and make mistakes. You will also have to work through them and seek to understand them. I would love to hear about some of the problems errors or bugs you faced that you ended up figuring out in the comments section!
Done Part 5 ðŸ‘ðŸ¼ Going to Part 6 ðŸƒðŸ¼â€â™‚
I've been slowly following along using data I was able to build a scraper for in my local real estate market. I think I have understood the process of everything to this point, but now that we are getting into making sense of the data, this is where I need to spend time learning what a lot of this means. I just got to the cross_val_score and I can't make heads or tails of what I'm looking at after reading a few brief reference sheets and articles.
Once again, great stuff. Quick question though (newbie here)... how come you didn't scale X_train and X_test prior to fitting your models? Or a more general question would be "Do you typically scale your X_train and X_test prior to fitting the data to your models?" I am primarily referring to non-tree models, like linear regression and lasso in this case. Thanks!
Thanks, this was a great series. One question I have is when you do the get_dummies, you are left with hundreds of columns, but when you productionize your model later on, would someone have to sit and fill hundreds of cells as data-in of your model? sorry if I am missing something obvious I am new to data science
Very awesome playlist! Ken youâ€™re giving people such a valuable resource. I took an intro data science class at Stanford and they literally teach everything you just went through but in 10 weeks! From data scraping to initial visualization and even model selection. We used Google Colab to code in and imo Colab works very well and is integrated with Google Drive so file sharing is easier for newcomers. Iâ€™m pointing anybody that wants to learn data science straight to you from now on!
4:05-Lasso Regression
4:40-Random Forest Classifier
4:50-Tune Models GridSearchCV
Hi Ken! Aren't we supposed to call the fit method on the Lasso model object that was instantiated ?
great work! very informative video, thank you!
Hi Ken, I am late to the party in both this video and data science in general, but I'm hoping to teach myself enough to make a career pivot into data science (I'd be happy to take a job as a data analyst at this point). From the perspective of someone that has done two or three "data analysis" projects on Kaggle (that were really just really sloppy jobs at cleaning and EDA) being able to go on the journey from start to finish with someone that is an actual professional leaves me more appreciative than I can possible articulate. Thanks for the videos
Wouldn't it be more robust if you scaled the data before making a model??
There are a lot of columns that have different ranges of values so wouldn't scaling be better before the ML part!
Great video;
Has anyone reproduced the results? I did it but I am getting some different results. Anyone up for discussion?
Amazing series, even now in 2022, as a new person in the area of data science this has been really helpful because I was really struggling with how to begin a data science project. Thank you for the content.  BTW, I don't know if you are aware of this now on 2022, but you can use #%% on a spyder script to execute portions of code like if it was a Jupyter notebook with shift + enter, I think is a little more efficient than highlight the code and do F5. Just in case you are not aware of this, although I think it all comes down to personal preference. 

Sorry if my grammar is weird, I'm not an English native lol.
Amazing video KenðŸ˜† It helped me started in Data Sience
Why did he / you ignore r studio column in df_model ?
Hi Ken,

Great videos as always. I followed this one until 12:07. I am seeing 1.000 for R-squared and 0 for all P-values. Back in part 2, when doing the scraper I had to cut the numbers down to 250 because the process kept disconnecting. During data cleaning that number was cut down to 38. Although the numbers were vastly different compared to yours, I was able to work with it because it still produced all of the insightful analysis. Now I'm unsure if I should continue because both R-squared and P-values look weird
Hi Ken, i love the way you are making the videos for the entire DS process. I would like to add a point for this video where I suggest if you have spent the feature selection process Or criterias to add more values to model and this video. Just my 2 cents for the video. It's good work done. Keep going. All the best
Jesus
Hi Ken ! i'm facing issue while importing  'import statsmodels.api as sm' , i have installed statsmodels already ,  the error is : 'ImportError: cannot import name 'datetools'.' please help
Whoa!!
You can just do:    max(error)  to get the max value in error list
For finding the best value for alpha, instead of making a data frame,
We can also do,

alpha[np.argmax(error)]

np.argmax(error) returns the index of the error and we can use it to get the alpha value.

Hope this helps.
Thanks for putting this all together. More explanations on the algorithms and metrics would have been even more helpful.
What is the reason you are picking the alpha with max(error) should we not be minimizing this?
This is a great overview of the modeling part of a data science project. It has inspired me a lot, thank you so much for this kind of content, Ken
This is an amazing series ðŸ’¯
hey ken , wonderful video i was wondering where did u get the eda_data.csv file because in the past video we didnt save any csv file???
One of the best series I've ever seen on youtube related to data science. Thank you so much for this amazing effort. Very inspiring and motivating. Highly appreciated, bro.
@Ken Jee We can't use Ridge regression in these kind of data because of sparse nature of dataset. Right?
Hello Ken, I have a question probably is a stupid one but I need an answer. How and in which step we got eda_data.csv file. I watched the videos but maybe I missed it. Thank you so much for your help.
good vid , im not sure but you insert alpa = .13 when in the lasso regression , not sure if its an mistake.
Hey Ken, newbie here but loving the series and would love to see more. Wondering what 'level' of data science this is. Is this quite similar to what a data scientist would actually be doing in a work environment?
i'm getting a straight horizontal line when i plot Lasso regression. any idea why that's happening?
for my case, the MAE  was 
Linear Regression MAE : 5.6690763194922056e-15
Random forest MAE: 0.015459375000001213

is it correct?
I did this on my own data and the r-squared is 0.15 and average of the mean absolute error is -592780108. Anyone got super off results like this?
Bro can u make more series like this? This inspires a lot
Iâ€™m working with a dataset containing around 100,000 rows and my grid search has been running for around 3 hours now (using the same parameters as you). Is this normal? Could Jupyter notebooks potentially be the problem?
Hi Ken, thank you for the fantastic video! I am having an issue with my linear regression, I was getting an error that my X_sm was an object so i converted it to a float, but my R-squared value is 1.0 which just doesn't seem to be correct. Any ideas? Thanks again!
Hey Ken!! Fantastic series.When you instantiated GridSearchCV as gs..and passed rf,parameters and scoring in it..it also requires verbose parameter..mine is not executing without verbose..(ps: am using jupyter notebook)
#This Lasso instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator. how to fix this error can't find anything in StackOverflow!
Hey Ken how would I use a combination of 2 models?
Hi Ken, at 12:00, when checking the multiple linear regression summary, for variables that has either very small coef (slope is close to zero) or p values smaller than 0.05 (statistically not significant), can we `safely` remove them from the regression model?
Another question is that, in my data, the multiple linear regression performs fairly well with the training data (use cross validation) but really bad on test data, is that caused by over-fitting? 
For Lasso and Random Forest, it's fine
Hi Ken, thank you for the tutorial, I have followed along from the beginning until here, I must admit that the most fun and useful part is to watching you got stuck by something and went through debugging. 

I have a question for dealing with missing data, in this example you consider "-1" for most categorical variables as a "new" category (by using dummies that's what it is in my understanding),  wouldn't it better to replace them with other forms or try to predict them using available values? It'd be great if you can share some insights on that. Thanks so much, please keep it up.
Another super helpful video. Thanks Ken!

Do you mind sharing a link to your Kaggle profile? I'd love to explore some more of your work.
Quick question: Would feature normalization and normalization of skewed data improve the results in this example or is it unnecessary? Any quick comment would help thanks.
At 11:58 when you wrote this code
X_sm = X = sm.add_constant(X)
model = sm.OLS(y,X_sm)
model.fit().summary()

After Writing this code i am getting this error
ValueError: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).

I have searched on StackOverflow , applied different solutions but none of them worked
If you also get an error message  (ValueError: DataFrame constructor not properly called!) when making the function to get the best alpha for the Lasso model :
err = list(zip(alpha,error))
instead of
err = tuple(zip(alpha,error))
Good Luck !
Hi Ken Jee, I have a question. So i m following your series (which is just so helpfull), and i tried to make some kind of a different approach without getting too far. I m making the same project, but instead of predicting the salary, i m predicting the "skills" required . Its about values from 0 to 3 : no degree/years of experience : 0, Bachelor : 1, Master : 2 and PhD : 3. Everything seem to work well until now. I made the linear regression model using sklearn and the result of the cross validation is extremely high beside the result i should have ([0:3]). So i tried to fluctuate the CV parameter, but it didn't change much. Do you have an idea of what could be wrong ? Thank you so much for your work !
Hi Ken. I have a request from you. Increase size of codes script for who watching you on mobile please. I know you sometimes zooming but thats not efficent.
Great series sir..! But I just wanted to ask what is the difference between using stats model & LinrearRegression() as I was usually using LinrearRegression() to train model so not getting the difference
This really is great stuff Ken!  Out of curiosity,  Why don't you have a patreon page or something?  You content is so valuable to aspiring data scientists, I'm sure people would want to support you.
I was also wondering, for the regression, since you use dummies, shouldn't you throw the base level of the categorical variables to solve any multicollinearity issues?
Hi Ken, very informative series. I would love other series like this dealing with other data science techniques such as deep learning, reinforcement learning or other machine learning techniques.
Thanks for shared your knowledge. 
One question. in before video "part 4" the file "eda_data.csv" did no exist. in this video you work with that file, where does it come from?. Thanks.
You make it look easy.. I am a beginner.
Your explanation is so Clear and easy to understand i learned so much from you ken
Great video Ken! 
One question: in the train test, it is common in the industry to train at .8 and test at .2? or does it depend on a factor that I don't know about, a brief answer will be greatly appreciated! Thanks!
Hey Ken I have a question, so Iâ€™ve been following your project step-by-step to see if I can do it myself and follow along. Thanks for that, itâ€™s great. Anyways, I canâ€™t help but keep doubting myself and thinking Iâ€™m not good enough, like when I get I stick I see what you would do or go to stack and see some answer I couldâ€™ve never thought of then I wonder how Iâ€™m ever going to make it in this field and be successful and then I get demotivated and stop studying, do you have any tips? Maybe something you went through thatâ€™s similar? Thank you.
I think one of the most important lessons of the video is: documentation is your best friend! Don't fear it, befriend it. Great video as always, Ken!
Really love your approach man.
So amazing to begin watching you before you began these series and then having this amazing 5 part lesson. There is no better teaching than practice, and you really just show practice. Excellent!
1st viewer i was waiting for it
I thought that this would be the last video of this series,  but I decided to do a BONUS one coming out Friday! That one will be on writing a solid readme for your projects that will appeal to employers!
Question: If I were to add user input to predict the salary, they would have to input all these data? 
'avg_salary','Rating','Size','Type of ownership','Industry','Sector','Revenue','num_comp','hourly','employer_provided', 'job_state','same_state','age','python_yn','spark','aws','excel','job_simp','seniority','desc_len'
this section was harder across before sections, I hope make more video to model productionize.
Thank you very much!!! Very good video series! Deploy video is great and very useful!
Thank you for the amazing series ,God bless you
Thank you for the amazing series. Was really helpful
really liked your work, we need more people like you. keep it up man!!
issue: 'touch' is not recognized as an internal or external command,
operable program or batch file.
what's the alternative command for touch in windows?
update: I did 'echo .>' command
this is not resolving altough i install git bash but cant figure it out
I didnt understand the part where we are making a request. For example if I am an end user, all I will be interested in is the salary for my position. So how would I be able to request that?
31:30: "Oh my goodness! It worked!" - The Golden Zenith of all Data Scientists! lol <3
The model was trained on around 178 features so how one should manually enter the data while accessing this project?
everybody kept telling me that Gunicorn do not work on windows but I made it work with some adjustments, great video though!
Hi Ken. Thanks a lot for this series. 
In this video I followed through till the request was made. After that I am constantly getting 
" x = request_json['input']
TypeError: 'NoneType' object is not subscriptable " error in flask and the output doesn't show. I have been trying to fix it since yesterday to no avail.
Great series Ken! Looking foward for the next one!
I want to ask one question so this part of series where I get struck because I don't understand it so is it okay that I like follow step by step this video do that ...I mean I still did a project but literally must have copied this thing so I am not sure what's your point view on this?ðŸ¥ºðŸ˜…
Heyy can you make a particular video on to choose which model should be used and like what are the most used model in general so in ML we learn that with great importance ðŸ’¯
Ps: I am taking too long to complete this series ðŸ¥´
Again, nice job. It was really helpful. Now I understand how a model code should look like and I also learned some tricks.

There is only one thing I think could have been better. Sometimes I couldn't understand what you were doing nor why. It felt like I was just watching you code.
I understand it is hard to explain everything while you are debugging or improving the model, but you could have added some explanations while editing.

Anyway, this doesn't take the value of the video. 

Many thanks!!
This is some good stuff Ken. I really like this series.
My chromedriver version is as per chrome browser so thats already uptodate.
what could be the reason for this error
This error is shown while I ran python 123.py
123.py --> I have renamed requests.py bcoz of package name 

Pls help out to solve it.
Is it bcoz of chromedriver installation or something else.



Error is:

Traceback (most recent call last):
  File "C:\Users\Monica\anaconda3\envs\ee3\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "C:\Users\Monica\anaconda3\envs\ee3\lib\site-packages\urllib3\connectionpool.py", line 727, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\Monica\anaconda3\envs\ee3\lib\site-packages\urllib3\util\retry.py", line 446, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001A860CDA048>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "123.py", line 14, in <module>
    r = requests.get(URL,headers=headers, json=data)
  File "C:\Users\Monica\anaconda3\envs\ee3\lib\site-packages\requests\api.py", line 76, in get
    return request('get', url, params=params, **kwargs)
  File "C:\Users\Monica\anaconda3\envs\ee3\lib\site-packages\requests\api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\Monica\anaconda3\envs\ee3\lib\site-packages\requests\sessions.py", line 530, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Monica\anaconda3\envs\ee3\lib\site-packages\requests\sessions.py", line 643, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Monica\anaconda3\envs\ee3\lib\site-packages\requests\adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001A860CDA048>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
Thanks a lot for this incredible video. 
I am not able to run the touch command in anaconda prompt probably cuz I work with windows 
issue: 'touch' is not recognized as an internal or external command,
operable program or batch file.
what's the alternative command for touch in windows?
update: I did 'echo .>' command
Congratulations Ken for this amazing videos series ! My huge Thank you for passing all the content in details and providing insights along a project. I'm a big fan of you and you help me out a lot during my journey in the Data Science field!
ken can you share some details regarding the project based on nlp and cv. man you videos are the best
This video is a bit hard for me to follow, so I tried some alternative and found someone else already mentioned in the comment, that is to use `Streamlit`, I personally find it easier to use to build the model into a web app compared to flask.
Hey, ken 'touch' is not recognized as an internal or external command, operable program or batch file'  how to solve this error? please help!
I am currently working on a data science project and was thinking of wrapping it up in a simple Django site. (more work than Flask but I think worth the effort) Do you usually make APIs out of projects? Does it sometimes come full circle as a full web app? I'm trying to stand out as an applicant.
Ken I'm not able to get the model as its showing : Buffer type mismatch 

File "sklearn\tree_tree.pyx", line 601, in sklearn.tree._tree.Tree.cinit
ValueError: Buffer dtype mismatch, expected 'SIZE_t' but got 'long long'

could you please help?
Hi Ken,

Could you please make a video on  Covid-19 prediction to attract recruiters post covid 19.

Thanks in advance :)
Nice work, you should do it more often, very practical and informative
Hi Ken. This has been a really helpful series for me!  
But, how did the command "touch" work for you? as it appears that it does not function in the Windows OS  and is definitely not working for me.
Hey Ken great videos!! I am a relative newbie and up until know I have been following along smoothly with no errors however with the step of running the "wsgi.py" file and running then curl X etc in the command line....I am getting the same error you were however the your fix did not work for me (@21:54 time stamp) and I made sure to copy the code you had to the letter.
Following Error:


<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<title>500 Internal Server Error</title>
<h1>Internal Server Error</h1>
<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>


Any ideas??
Sean
Great tutorials! Have you considered trying streamlit for publishing the â€žappâ€œ?
Ken, I can't over emphasize the importance of this video series to me. Practical, insightful and indepth.Using real life practical examples. keep up the good work.. much thanks
Hey Ken.... I'm building a ML model in google colab can I make rest API using google colab
Please donâ€™t stop making data science videos, Ken. Incredible stuff. More sports analysis/models potentially?
Great content â¤ï¸â¤ï¸ðŸ‘
Hey Ken, great video as always! I was wondering whether next you could create a step by step introductory guide to GitHub and how to properly use it to store our projects after creating them on jupyter notebooks!
Looking forward to your reply!
Very excited that we get another video! You're a saint, Ken!
â€‹Sir, can you do a project on healthcare/Medical or 1 video in which we follow your guidelines to do a project on it.
Really enjoyed this series. As someone learning the field I loved the practicality of it!

A video on the best resources for learning the right models to use in which scenarios would be great too!
Ohh, it mean we have to learn flask also..  to become a data scientist?
Awesome video dude.....coool.....
Earlier than I expected. Awesome! Already told my friend about your vids
Thank you so much i did it finally . It took 2 weeks to complete whole code from scratch
Great work Ken, the only thing I'd suggest in the technical part to clean up the repo, so we don't end up having binaries, caches... along with the code. Good luck.
This is great ken! Since I was following this series tangentially, I got to learn web scraping, lasso regression, flask and API (you explained that amazingly well), and proper documentation (which i feel is an underrated skill). 

Thank you and hope to see more amazing content! Take care.
This is amazing. The whole journey including hick-ups and subsequent search for the solutions, and final resolutions, explanations, and documentations is just priceless. Thanks for taking time to put this together to help others. Keep it up.
amazing
Thank you for this very well structured project series. As I am new to the DS field, I received many important ideas and insights and you are really a gem â¤
That was really useful!! Thank you! :)))
Thank you! Documentation is so important and one does not often learn about it until it becomes a problem that there is no documentation. This video was really helpful in getting an idea of what is a good documentation practice for a data scientist.
Completed this Awesome project series â¤. This project teach me so many things and motivates me towards Data science.
Thank you Ken
Thanks for the series. You are amazing!
The best compliment I can give to this 4+ hour playlist is... I'm going to watch it again in the near future. It was great -- thank you for putting in the time to make it.
I liked watching all the videos with your in-depth work. What I though was missing is an example of how it work when a user sent the information to the server and how and what information was displayed, the end product that provide information so that the user can make a decision from the data.
amazinggg you're so great ken. Thank you again I've told all my DS homies about you. Thank you!!
Thank you for the series, most transparent I've seen on yoUtube
Thanks this was really heplful to me ! i think i can start documenting my projects now!
Hi Ken! Like everyone else I'm super grateful for this series -- it was so detailed and helpful. I'm a recent university graduate (data science major) and this helped synthesize everything I learned into something actually cool and useful! I'm about to apply for entry level jobs and cannot thank you enough for all the effort you put into this. :)
Just finished watching this project series. It is really helpful to understand the whole process of working on a project. You have done a great job.
What an absolute gem of a playlist. Thank you so much Ken! You are a star
man i finished the project because of u thanks a lot u r my hero
Thank you for doing this whole series. I hope you do another one soon! Your videos are so great for learning
Thanks Ken this project tutorial is great.
I watched all 7 and will be referring to it often! Great work and thanks Ken!
Need this kind of content...PERFECT
Great Playlist, loved it! One feedback would be to focus the screen share on the coding part of Spyder, it is tough to follow because the code is just a small part of the screen.
Hey! I'm learning data science from 3 months and I have completed probability, some part of stats and python, now I'm learning Linear regression and clustering. I have not yet started with the deep learning concepts. But I want to start my project now and build the project along side the theory do u think that is a good idea? Also at this level is it good to start with this series or will I be confused as I don't know many concepts? Also I am self learner so if you would reply it would be of a great helpðŸ˜
Great video ! I just binge watched the whole playlist ðŸ˜
Just a quick stream question: how do you deal with a super wide monitor and  sharing your screen at normal aspect ratio with OBS ?
It was a journey. I am about to finish my project and I can't thank you enough.  Hadn't I followed this playlist, my final project would be simply a bunch of code that no one would understand.
Thanks again Ken.
Thank you so much Ken. When someone loves the subject and teaches it to others, they will also start loving the subject. With your detailed unedited video, I gained a lot of confidence. I used to get overwhelmed with so many terms but seeing you I understood that not everyone knows everything. You just have to start with an idea and learn along the way by getting your hands dirty. Thank you once again. Have a great day!
Thank u so much for this series, it really gives me a lot of insights^^
This series deserves a Netflix production! Geat job Ken, so helpful !
I loved this series! Thankyou for giving us the time to make this, they're so helpful for people like us, please make more :')
Made it to the last video of the series! Yey! thxs for all this, I was getting anxious because I wasn't sure how to structure and use all the tools I'm getting from the courses/videos/books/etc. in an actual project, and this was really helpful :D
Bloody well done mate!!
Watched this full series. It's a great one. One thing I found when you were correcting hourly to annual wage ,you need to calculate Average salary again . As after doing hourly to annual wage min and max salary got changed.
Thanks
Thanks for the series Ken I really appreciate it! Small detail though, but it looks like the y-axis on the histogram in your EDA is labeled "job_state" when it should be something like "num_job_postings".
Hi Ken wanted to ask if its possible to make an API endpoint that takes in multiple rows or a file and outputs predictions for each row in that file at once
HI, Ken Please make more videos on end to end project like this starting from data collection to documentation
Thank you ken, i never thought i would come this far in data science and you made it much easier to understand.
Hi Ken, really appreciate the time and effort covering the technical aspects of data science as opposed to just a generic theoretical road map suggested by many. Helps to put things into perspective for those keen in this field. Great work btw!
Thank you so much ken for Markdown cheatsheet and for providing all the valuable information through this project whole series finally completed the whole series still facing few problems, error but I will try to solve it...keep making videos like this...best wishes for your channel...Thank you once again!!!!
Learned a lot from this series Ken. Thank you soo much and hope you will add more projects like this in the future. Can you take up a really messy dataset and guide us on the cleaning part as a video?
YouTuber of the YEAR!!!!
This is amazing series thanks it helped me a lot ...
I really enjoyed your series, thank you :) It was very fulfilling to see all the theory I've been learning in my Masters in such an easily understandable and interesting approach. New subscriber!
Thanks, this series was really useful to see what goes into a good project from beginning to end! I loved the honesty and openness (including how you showed the debugging process and where you copied code from online whenever you got stuck on something)
Dude, this whole series is awesome. Thank you thank you thank you.
Great and informative series! Keep it up
Great Series Ken! Very informative and easy to comprehend from a novices perspective. One question I do have and forgive me if I am not understanding this project correctly but how do we use this tool practically? We are able to scrap the listings from glass door and ultimately make a model to estimate an avg salary for a job but when it is all finished is this a tool where we can plug in a job title and a set of skills or something and it returns an average estimated salary for said job (for maybe salary negotiations of a current position etc.)? Sorry if this went over my head when going over the project!

Keep up the good work and I will continue to follow along!
Sean
Thank you so much Sir for this series. I hope to watch like this in future.
Thnx a lot man, this was fantastic!! Looking forward for your next projects. I would suggest: 'Sentiment Analyses' thnx again for your hard work
I really enjoyed watching your videos. To be honest i worked with the same Glassdoor dataset you used, but now i'm planning on doing the same steps with another dataset.
Wonderful Series Ken, just watched it. I Learned a lot throughout the videos, thank you.
Looking forward to the next series.
Give this man a biscuit. You have helped me obtain direction on how I should go about my projects. I will be referring to this series often. Again, you're a star.
damn man!! your honesty for this data science topic made me subscribe your channel and your content as well.  I'm also doing some online data science courses.  Love from India.
Thank you so much for this series!! As a freshman getting my bachelors in data science, this series helped me out a lot in terms of what to do when creating a project and how to overcome obstacles. Currently, we are just learning how to code and havenâ€™t gone through the whole process as you showed us in this amazing series. So, I wanted to ask you if thereâ€™s anything you suggest for me to do this summer to learn more skills and gain more experience in the data science field ?
Thanks for creating this series. Watched and liked all 7 parts back to back.  Very informational and useful.  Looking forward to learn more from you.
thanks so much for these indepth walkthroughs.
Really a super awesome series ken. It helped a lot to every DS enthusiasts .
loved this series Ken!
keep doing great work man
Hi Everyone! Thank you for watching this series. It has gotten far better feedback than I could have imagined and I am grateful for everyone who has watched it. Again, I hope that it was helpful to you! Let me know below if you would like to see more videos like this, and what if anything you would change about this series. Thanks!
Interested in knowing more?
atoti is hosting a live stream MasterClass on November 18th.
Join the atoti team as we demonstrate how to extract value from sales data!
session = tt.Session()
session = tt.Session(config={'user_content_storage': './content', 'port': 9000})

mine works with this i found on chat gpt.
is there an update in atoti?
In line 16, i.e. tt.create_session(â€¦) it is showing an attribute error that no such attribute (create_session) is found

Could you please help with this
Hey, could you please help me, I have even installed it but I have the following error.

 ---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
~\AppData\Local\Temp/ipykernel_13888/26498132.py in <module>
----> 1 import atoti as tt
      2 session = tt.create_session()

~\anaconda3\lib\site-packages\atoti\__init__.py in <module>
     76 (_LICENSE_END_DATE, _IS_COMMUNITY_LICENSE) = retrieve_info_from_jar()
     77 
---> 78 check_license(_LICENSE_END_DATE, _IS_COMMUNITY_LICENSE)
     79 
     80 register_active_plugins()

~\anaconda3\lib\site-packages\atoti\_licensing.py in check_license(end_date, is_community_license)
    159     for output in get_license_outputs(end_date, is_community_license):
    160         if output.output_type == OutputType.EXCEPTION:
--> 161             raise Exception(output.content)
    162         if output.output_type == OutputType.REGULAR:
    163             print(output.content)

Exception: Your license has expired, contact ActiveViam to get a new license.
The most important part of this video is the explanation of how you figure out to replace the ().  I am going on 9 years as an analyst and still more days then not I am googling something I don't know how to do yet.  Keep up the good work Ken!
Hi

how can we deploy this as a webapp on heroku?
waiting for your reply please :(
imho nothing looks better than dash plotly
18:25 "I also want to do just a little bit more data manipulation" .... said no one ever ðŸ˜³jk
awesome tutorial!! Really craving a burrito now ðŸŒ¯
Hey, Thank you Ken.  I liked the approch via atoti
Would be cool to do a comparison of this package, Streamlit, and Dash!
I love burritos and the fact you made a dashboard made me take interest in dashboards & incorporating some dashboard into my portfolio. Productive Saturday so far thanka to you! ðŸ™
You finally created another project video!!!  Thank you Ken!!

Your last data science project series was the #1 reason I have my current data science role! 

Thank you for providing quality data science content and never stop. Can't thank you enough.
Dashboards are always beautiful... Great and helpful video... ðŸ™Œ
Ken do be looking buff in this t-shirt
It's always fun and informative to learn the thought process behind the analysis. Great video Ken! Burritos, yummy ðŸŒ¯

Thanks for watching everyone! Be sure to follow along with the code here: https://github.com/atoti/notebooks/tree/master/notebooks/burritos
I hope you all will join me on this project! Link to the data: https://www.kaggle.com/kenjee/ken-jee-youtube-data
This could be a great one to engage with on your #66daysofdata journey!
Iâ€™m new but Iâ€™ll give it a try over summer, college finishes in 3 weeks ðŸ¤
Ken,

Thanks for inspiring me to follow my passions through your content. I was working as a financial advisor and hated my life and you gave me the confidence i needed to make the leap and study data science. I'm almost done with my first project and owe a lot of my confidence to you. Keep it up!
No I think not :pepe_hands:
How long do we have?
This is such a wonderful iniative! Looking forward to tinkering around with the data you have shared!
HI Ken! How about a video on how did you extract and arrange this data?
The keyword "Papaya" spikes view counts
Uni exams but I'm so excited about this!
This is cool. Iâ€™ll try it out! Thanks Ken!
It also helps me knowing the kind of data science questions to ask in my workplace.
Awesome, this is going to be fun, feel free to count me in as one of your staff for Staffâ€™s favorites? ðŸ¤”
Well, even though I don't how to do, I'm still gonna try..
Thanks
Wow, this is such a cool way to engage with the community. Thanks Ken.
I bet I can make a better pizza.
thank you for this! iâ€™ve been looking for projects to tackle
Been listening your podcast. This is good time to start with.. Will definitely look into it.
Wow, That's will be exciting to participate ðŸ™Œ
Bam
As a product director I'm itching to get my hands into those dataset and find some potential insights on what could have highest impact on your product ;)
That's so amazing!! ... Definitely gonna try ðŸ‘
To answer the video title.... I can't ðŸ˜­... BUT I'm gonna sure try!!! ðŸ™ŒðŸ¼

#PapayasIncToTheMoon ðŸš€ðŸˆ
This project is unique.....
A data Scientist asking Data scientists to use data science to solve a data scientists questions. 

All in the name of cracking the YouTube algorithm. This is exciting!! Already working on ideas
Iâ€™ll participate for sure!! ðŸ˜€
Such a fun idea and data set! Iâ€™m going to send this to my students and have them work on it!
This is Amazing!!!!
I am Excited to work on it and also thank you so much for sharing the data.
This can be a great chance for everyone to learn and do something innovative and creative :)
That's really cool!
Lumayan nih, harus dicoba buat mengasah skill analisaðŸ‘
Great!
I was also in search of any beginner ml project from Kaggle cuz I just completed learning supervised learning so wanting try some of the projects
This is so cool Ken ! Thank you for the efforts ðŸŒ» I will definitely participate
Check out the #30DaysOfStreamlit here! https://share.streamlit.io/streamlit/30days. Again, this is a great learning objective that can be done alongside the #66DaysOfData!
Great work, Ken. Kindly share your source code.
I do find the data in your kaggle. I do not find the script from the vid. Any help? Thanks. Thanks for the vid also. Very insightful.
I have trouble to run streamlit , then decide to do it on flask. Please advise
Instant sub, Great vid!
Hi, Ken - great video here. I wondered if you have more guidance around how you grabbed your dataset using the youtube API? I am thinking about getting the data from another channel and would love your input there.
Im a self taught and still learning basics of python, my career path will be data analyst or data science. 
Thanks for end to end tutorial . Awesome ðŸ˜ŽðŸ‘
I'll give it another try... but for now impossible to pass the initial install steps.
trying with venv and pip + requirements
... always some myterious dependency problems.
Anyway, tutorial sounds amazing and I'll come back once I have the patience or a clean computer.

AFTER A FEW DAYS ...
Tutorial is very good and I finaly got it working. However, it was easier for me to do it without conda and relying on the things I know pyenv and pip and it works just fine on python 3.10.
Thanks for your excellent work.ðŸ˜€
It's a great video.
Thank you so much for such a good project. Would love to go along with more projects from scratch.
Hi Ken, Thank you so much for this project. It's an eye-opener. I have a problem though, my publish date column is also implementing colors. I would appreciate it if you could help me understand that better, Thanks again
Ken thank you so much for those videos! I was wondering if you could make a video about creating your own dataset/data scraping for portfolio project? Thanks:)
Hello, is it possible to use this project and show this data as a web interactive app that the user might interact with?
Hello Ken!
U am bew to Data Science and I really love your channel & content. I have a major in Food Science and I want to make a huge change to my life going into Data Science. What online complete course do you recommend for me to get please?
woww this video is a wonderful video and pushed me to some other videos in your channel. great content. thanks for uploads. ,.,.,.,.
Wow, this is exactly what i looking for! Thx Ken Jee
Is it necessary to create a python environment first?
Thanks for this video sir. Please make more like this ðŸ™
Great video but maybe use a 16:9 monitor to record your videos.
Saya sangat suka betapa mudahnya projek ini untuk menjana wang tanpa terlalu banyak kerumitan. Saya suka sangat. Anda juga boleh mencuba.
00:01:50
Ooof I missed this from scratch series
always love when my favorite papayaManager drops such a sweet video <3
Let's do this!!
Super Informative video, but for some reasons I cant figure out how do you  run the code into the streamlit application page
Could you please share the same
this is the asian version of tailopez
Ken thanks so much for this I think these interactive video's where a complete data science project is worked through is what I've been missing
PROJECT FROM SCRATCH! Could you make an NFT of beepbeep next c:
For some reason I did not get the notif of this vid? wtf youtube, anyway CONGRATS on getting streamlit to sponsor your vid , lovely vid btw <3
Another installment of Ken's infamous Project from Scratch series!!

Thank you for continuing to make these videos Ken! Will be creating this for my portfolio.

It truly is amazing how such powerful and visually appealing dashboards can be created AND publicly displayed with Streamlit ðŸ‘
Woah this is super nice Ken!! Love that you walked us through your thought process in the feature engineering part. And bless you at 10:48 ðŸ˜„ (appreciate that you didnâ€™t cut it out!)
You're always reading my mind. I got done with one of your Youtube datasets and was thinking of how to put the plots/visuals in a dashboard, but Dash seems overwhelming a bit. I'll study this tonight! Thank you again
Streamlit is super awesome! I use it for visualization in a lot of my courses. It's so easy to work with because it's Python. Deployment as Docker containers is also very good. I cannot recommend it enough. Great video Ken. What do you think of the recent purchase of Streamlit by Snowflake? Will that give it a big boost?
This is a fantastic video. Your channel is truly a gem. Not only for learning about coding part, but I really appreciate the opportunity to compare my current skill set to what is expected when I get my first ds job. Thank you, thank you.
10:48 Bless you!
It's been waaaaayy too long since we've had a Project from Scratch video, Ken! 
Loved seeing Streamlit being implemented in this!
Glad you kept contextualizing decisions in context of the use case. That is something that more people need to understand. 

PS: Emailed you as discussed. Did you receive it?
Haven't used streamlit before but definitely have to now ðŸ˜
You could do a quick open tabs video just for fun if thatâ€™s your thing. Similar to what Bert Kreischer does. Who knows might be funny or interesting.
*That is a fantastic project!* Thanks for the complete walkthrough!
Love Streamlit! Been using them at work and for fun for over a year now. Love these detailed tutorials as well
Wow i was just doing Data science Jobs project and here,s another.
Ooo it's been a while since we had similar project videos I like watching these ..  For the requirements.txt file I just add the modules that I used but after a quick google search it seems like adding everything is better for 2nd+ degree dependency versions ? This makes it easier lol ! Great video Ken Thank you !!!
Wow, that's a great end-to-end tutorial from the thought process, setting up the development environment, data wrangling and finally putting everything together in the dashboard app.
Cool Stuff! Definitely gonna try streamlit to build a dashboard of some sort.
It's amazing how easy it is these days to build visually appealing dashboards.
Kaggle Notebook (Housing): https://www.kaggle.com/code/kenjee/housing-prices-example-with-video-walkthrough 
Check out the video description for additional resources!
What was the use of Data Exploration? I feel it played no part whatsoever in the final results of the project.
I've been trying to become a data analyst for 2 years, no luck. But data scientists roles are looking more attractive now though, they seem more programming focused and pay a lot more.

As far as I can see from the table of contents, the model part is when it turns into data scientist role? I think a Data Analyst would stop st the EDA and then create visuals. Still tryung to figure out the difference between the two! 

Btw are junior data sci roles easier to land that junior data analyst? All the data roles ive seen at entry level want 3 years experience..

Im any case im gonna follow along here as I have experience with pandas and Python, thanks!
This has been very informative to see the process and how you included AI in it.
Half way through and just wanted to say this is very valuble content! Love the walkthrough type if content!
You are amazing - this helped me so much - I am on the beginning of my journey and trying to find videos like this where people walk through what they've done. Yours is the best I've come across so far! TY!
Thank you Ken!!! I had no idea on how to do a kaggle challenge or what was expected, but you went through the whole process and explained what each part was!!! Now I have no excuses for a boring kaggle profile
Hi Ken! thanks for making this great tutorial. Can you do tutorial on fine tuning the NLP pretrained model? there are few videos out there but I think you are more advanced on communicating the technical things so it's make us easier to understand. Thanks!
Being on a hill also means less risk of water damage given any runoff will flow downhill.  I'm assuming a depression is opposite and runoff will flow and pool towards the hoke
Hey Ken, have you tried using ChatGPT with Noteable plugin to help you solve a Kaggle competition? I used it and it works (https://www.youtube.com/watch?v=iIKfJT5QF_I), I think people will enjoy if you made a video using that
Thanks Ken for the tutorials. I'm not really a fan of your videos because they're not technical enough but I really enjoyed this and learnt a couple of things. Wish you could make more of these
I am a material scientists who works with large data sets and I want to pivot into data science because I've grown to love how data is manipulated and analyzed outside of just scientific applications.  academia has been exhausting and I want to refresh things in a new field.  Do you by chance do any personal life coaching??  regardless, thank you for your videos, they are both motivational and instructional!!
Really AMAZING video! Helps me on my grad journey breaking into data jobs
Amazing Work Ken. Thank you for explaining so thoroughly :)
This project is amazing! Can you make more videos like that please?
Thanks for the video, Ken. But with all due respect, it's less of a data science tutorial and more of a ChatGPT demo.
Hey sir, I would wanna know about this, would you recommend using powerbi for EDA process before model building than pandas?
Where have you used chatgpt?
Wonderful content as always.

But you could literally reset the default theme to 'plotly_dark'. This would have been better than repeating most of the layout update.
I think to make the code less confusing, the y_test could be replaced by y_valid like some notebooks did so the test suffix is reserved for the real test data.

Thank you for your wonderful videos and your codes are always so clean and easy to follow! Cheers!
Hi Ken! Have you had to utilize PCA before?
As a practicing data scientist, how important would you say it is to handle calculations such as integrals by hand? I studied this stuff 10 years ago and have since had my skills atrophy. Though the intuition is still there. Is it worth going through that stuff again or just diving into the deep end?
My nga, ure the best!!!
Can you make a whole playlist where you go through different projects because you have a very unique way of teaching and I think a lot of people would benefit from that
can you make a playlist for upcoming projects
Sometimes I think i picked the worst year to get into DS , I do love the field, really do, but when the market requires PHD for entry levels.. you know you got yourself into big trouble
Thank you for explaining this so well! As a beginner this gave me invaluable insight on how to approach a problem on Kaggle.
Immedietly i saw this video i also started creating the same project ðŸ¤£ thanks !!!!
Data science is dead lol
Great Timing!!Thanks.. following  to u with closely
